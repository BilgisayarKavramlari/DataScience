{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/shedai/intro-textprocesing?scriptVersionId=246331513\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"2415987f","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-06-19T12:28:19.353392Z","iopub.status.busy":"2025-06-19T12:28:19.353071Z","iopub.status.idle":"2025-06-19T12:28:21.232282Z","shell.execute_reply":"2025-06-19T12:28:21.231312Z"},"papermill":{"duration":1.885125,"end_time":"2025-06-19T12:28:21.234209","exception":false,"start_time":"2025-06-19T12:28:19.349084","status":"completed"},"tags":[]},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"id":"c19a9154","metadata":{"execution":{"iopub.execute_input":"2025-06-19T12:28:21.240966Z","iopub.status.busy":"2025-06-19T12:28:21.240496Z","iopub.status.idle":"2025-06-19T12:28:21.246204Z","shell.execute_reply":"2025-06-19T12:28:21.245313Z"},"papermill":{"duration":0.010351,"end_time":"2025-06-19T12:28:21.247608","exception":false,"start_time":"2025-06-19T12:28:21.237257","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Start Index: 4\n","End Index: 8\n"]}],"source":["import re \n","s = \"Turkcell\"\n","\n","match = re.search(\"cell\", s) \n","\n","print(\"Start Index:\", match.start()) \n","print(\"End Index:\", match.end()) "]},{"cell_type":"code","execution_count":3,"id":"b66cbb10","metadata":{"execution":{"iopub.execute_input":"2025-06-19T12:28:21.253521Z","iopub.status.busy":"2025-06-19T12:28:21.253203Z","iopub.status.idle":"2025-06-19T12:28:21.259378Z","shell.execute_reply":"2025-06-19T12:28:21.258209Z"},"papermill":{"duration":0.011038,"end_time":"2025-06-19T12:28:21.261017","exception":false,"start_time":"2025-06-19T12:28:21.249979","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Start Index: 0\n","End Index: 24\n"]}],"source":["import re \n","s = \"Turkcell@turkcell.com.tr\"\n","match = re.search(\"^([a-zA-Z0-9_\\-\\.]+)@([a-zA-Z0-9_\\-\\.]+)\\.([a-zA-Z]{2,5})\", s) \n","print(\"Start Index:\", match.start()) \n","print(\"End Index:\", match.end()) "]},{"cell_type":"code","execution_count":4,"id":"9c17d00a","metadata":{"execution":{"iopub.execute_input":"2025-06-19T12:28:21.267297Z","iopub.status.busy":"2025-06-19T12:28:21.266875Z","iopub.status.idle":"2025-06-19T12:28:21.273824Z","shell.execute_reply":"2025-06-19T12:28:21.272837Z"},"papermill":{"duration":0.011998,"end_time":"2025-06-19T12:28:21.275476","exception":false,"start_time":"2025-06-19T12:28:21.263478","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Match at index 14, 21\n","Full match: June 24\n","Month: June\n","Day: 24\n"]}],"source":["import re\n","regex = r\"([a-zA-Z]+) (\\d+)\"\n","\n","match = re.search(regex, \"I was born on June 24\")\n","if match != None:\n","    print (\"Match at index %s, %s\" % (match.start(), match.end()))\n","    print (\"Full match: %s\" % (match.group(0)))\n","    print (\"Month: %s\" % (match.group(1)))\n","    print (\"Day: %s\" % (match.group(2)))\n","\n","else: \n","    print (\"The regex pattern does not match.\")"]},{"cell_type":"code","execution_count":5,"id":"ea99e9af","metadata":{"execution":{"iopub.execute_input":"2025-06-19T12:28:21.282131Z","iopub.status.busy":"2025-06-19T12:28:21.281731Z","iopub.status.idle":"2025-06-19T12:28:22.80196Z","shell.execute_reply":"2025-06-19T12:28:22.800833Z"},"papermill":{"duration":1.525375,"end_time":"2025-06-19T12:28:22.803645","exception":false,"start_time":"2025-06-19T12:28:21.27827","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["[[1 1 1 1]]\n","[[0 0 1 1]]\n","['bağlan' 'hayata' 'ile' 'turkcell']\n"]}],"source":["# creating the feature matrix \n","from sklearn.feature_extraction.text import CountVectorizer\n","ans = \"Turkcell ile bağlan hayata\"\n","ans2 = \"Turkcell ile dünyalar senin olsun\"\n","matrix = CountVectorizer(max_features=1000)\n","X = matrix.fit_transform([ans]).toarray()\n","print(X)\n","X2 = matrix.transform([ans2]).toarray()\n","print(X2)\n","\n","print(matrix.get_feature_names_out())"]},{"cell_type":"code","execution_count":6,"id":"84f989e8","metadata":{"execution":{"iopub.execute_input":"2025-06-19T12:28:22.810041Z","iopub.status.busy":"2025-06-19T12:28:22.809611Z","iopub.status.idle":"2025-06-19T12:28:23.078513Z","shell.execute_reply":"2025-06-19T12:28:23.07622Z"},"papermill":{"duration":0.274145,"end_time":"2025-06-19T12:28:23.080458","exception":false,"start_time":"2025-06-19T12:28:22.806313","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00         1\n","           1       0.50      0.50      0.50         2\n","\n","    accuracy                           0.33         3\n","   macro avg       0.25      0.25      0.25         3\n","weighted avg       0.33      0.33      0.33         3\n","\n","'I love the experience' -> Pozitif\n","'I feel terrible' -> Pozitif\n","'What a wonderful day' -> Pozitif\n","'This is not good' -> Negatif\n"]}],"source":["from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","\n","# Örnek veri kümesi (pozitif ve negatif cümleler)\n","# Corpus / külliyat / derlem\n","texts = [\n","    \"I love this product\",       # pozitif\n","    \"This is an amazing movie\",  # pozitif\n","    \"I am very happy with the service\",  # pozitif\n","    \"I hate this thing\",         # negatif\n","    \"This is the worst experience ever\", # negatif\n","    \"I am not happy with this\",  # negatif\n","    \"I feel wonderful\", #positif\n","    \"I love the product\", #positif\n","]\n","labels = [1, 1, 1, 0, 0, 0, 1, 1]  # 1 = pozitif, 0 = negatif\n","\n","# Metinleri vektöre çevir\n","vectorizer = CountVectorizer()\n","X = vectorizer.fit_transform(texts)\n","# Veri setini eğitim/test olarak ayır\n","X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, random_state=42)\n","\n","# Lojistik regresyon modeli\n","model = LogisticRegression()\n","model.fit(X_train, y_train)\n","\n","# Tahmin yap ve sonucu değerlendir\n","y_pred = model.predict(X_test)\n","print(classification_report(y_test, y_pred))\n","\n","# Yeni metinleri tahmin et\n","new_texts = [\"I love the experience\", \"I feel terrible\", \"What a wonderful day\", \"This is not good\"]\n","new_X = vectorizer.transform(new_texts)\n","predictions = model.predict(new_X)\n","\n","# Sonuçları göster\n","for text, label in zip(new_texts, predictions):\n","    sentiment = \"Pozitif\" if label == 1 else \"Negatif\"\n","    print(f\"'{text}' -> {sentiment}\")"]},{"cell_type":"code","execution_count":7,"id":"bac807a2","metadata":{"execution":{"iopub.execute_input":"2025-06-19T12:28:23.090581Z","iopub.status.busy":"2025-06-19T12:28:23.090184Z","iopub.status.idle":"2025-06-19T12:28:23.894578Z","shell.execute_reply":"2025-06-19T12:28:23.893526Z"},"papermill":{"duration":0.811473,"end_time":"2025-06-19T12:28:23.896052","exception":false,"start_time":"2025-06-19T12:28:23.084579","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Sentiment Analizi (TextBlob):\n","'I love this product' -> Pozitif (0.50)\n","'This is terrible' -> Negatif (-1.00)\n","'What a great day!' -> Pozitif (1.00)\n","'I hate this' -> Negatif (-0.80)\n","'It's okay, not bad' -> Pozitif (0.42)\n"]}],"source":["from textblob import TextBlob\n","\n","# İngilizce örnekler\n","texts = [\n","    \"I love this product\",\n","    \"This is terrible\",\n","    \"What a great day!\",\n","    \"I hate this\",\n","    \"It's okay, not bad\"\n","]\n","\n","print(\"Sentiment Analizi (TextBlob):\")\n","for text in texts:\n","    blob = TextBlob(text)\n","    polarity = blob.sentiment.polarity\n","    label = \"Pozitif\" if polarity > 0 else \"Negatif\" if polarity < 0 else \"Nötr\"\n","    print(f\"'{text}' -> {label} ({polarity:.2f})\")"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"papermill":{"default_parameters":{},"duration":10.043142,"end_time":"2025-06-19T12:28:24.620193","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-06-19T12:28:14.577051","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}