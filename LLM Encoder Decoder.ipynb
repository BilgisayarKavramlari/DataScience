{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/shedai/llm-encoder-decoder?scriptVersionId=249028445\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"c2e2e3cc","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-07-06T06:28:00.849822Z","iopub.status.busy":"2025-07-06T06:28:00.849446Z","iopub.status.idle":"2025-07-06T06:28:02.829396Z","shell.execute_reply":"2025-07-06T06:28:02.828455Z"},"papermill":{"duration":1.991536,"end_time":"2025-07-06T06:28:02.831244","exception":false,"start_time":"2025-07-06T06:28:00.839708","status":"completed"},"tags":[]},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"markdown","id":"4b9995f1","metadata":{"papermill":{"duration":0.006349,"end_time":"2025-07-06T06:28:02.845713","exception":false,"start_time":"2025-07-06T06:28:02.839364","status":"completed"},"tags":[]},"source":["Encoder-Decoder mimarisinin nasıl çalıştığını, iki bölümün birbiriyle nasıl konuştuğunu ve adım adım bir çıktının nasıl üretildiğini gösteren, gerçek bir sinir ağı içeren bir kod örneği hazırladım.\n","\n","Bu örnekte, simülasyon yerine PyTorch kütüphanesini kullanarak, basit bir çeviri görevini (İngilizce sayılardan Türkçe sayılara) yerine getiren, çalışan bir Encoder-Decoder modeli oluşturacağız. Kod, her aşamada neler olduğunu anlamanızı kolaylaştıracak şekilde bolca açıklama ve ara çıktı içerir.\n","\n","Senaryo: Basit Bir \"Sayı Çevirmeni\"\n","\n","Görev: \"one\" -> \"bir\", \"two\" -> \"iki\" gibi basit çeviriler yapmak.\n","\n","Mimari: Klasik ve anlaşılması kolay olan RNN (GRU) tabanlı bir Encoder-Decoder modeli kullanacağız. Bu, Transformer'dan önceki temel Seq2Seq yapısıdır ve mimarinin temel mantığını anlamak için mükemmeldir.\n","\n","Adımlar:\n","\n","* Veri Hazırlığı: İngilizce ve Türkçe kelimeler için ayrı sözlükler oluşturacağız.\n","\n","* Encoder Modeli: İngilizce cümleyi okuyup bir \"anlam vektörüne\" (context vector) dönüştürecek.\n","\n","* Decoder Modeli: Bu anlam vektörünü alıp adım adım Türkçe çıktıyı üretecek.\n","\n","* Eğitim: Modelin bu çeviriyi nasıl öğrendiğini göreceğiz.\n","\n","* Test: Eğitilmiş modelle yeni bir çeviri yapacağız."]},{"cell_type":"markdown","id":"a5bff48b","metadata":{"papermill":{"duration":0.006077,"end_time":"2025-07-06T06:28:02.85822","exception":false,"start_time":"2025-07-06T06:28:02.852143","status":"completed"},"tags":[]},"source":["# Basit Encoder-Decoder Yapısı"]},{"cell_type":"code","execution_count":2,"id":"2487a7e0","metadata":{"execution":{"iopub.execute_input":"2025-07-06T06:28:02.873033Z","iopub.status.busy":"2025-07-06T06:28:02.872607Z","iopub.status.idle":"2025-07-06T06:28:17.893994Z","shell.execute_reply":"2025-07-06T06:28:17.892729Z"},"papermill":{"duration":15.031208,"end_time":"2025-07-06T06:28:17.895816","exception":false,"start_time":"2025-07-06T06:28:02.864608","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["--- Adım 1: Veri Hazırlığı ---\n","İngilizce Kelime Sayısı: 12\n","Türkçe Kelime Sayısı: 12\n","Örnek: 'one' -> 2, 'bir' -> 2\n","\n","============================================================\n","\n","--- Adım 2: Encoder ve Decoder Modelleri ---\n","Encoder ve Decoder modelleri (RNN-GRU tabanlı) tanımlandı.\n","\n","============================================================\n","\n","--- Adım 3: Modelin Eğitimi ---\n","\n","1000 iterasyonluk eğitim başlıyor...\n","\n","\n",">>> 'ten' kelimesi işleniyor...\n","1. ENCODER çalışıyor: Girdi okunuyor...\n","2. ENCODER tamamlandı. 'Anlam Özeti' (Context Vector) oluşturuldu.\n","   Context Vector (encoder_hidden) boyutu: torch.Size([1, 1, 128])\n","\n","3. DECODER çalışıyor: Adım adım çeviri üretiliyor...\n","   -> Adım 1: Tahmin='on', Gerçek Hedef='on'\n","   -> Adım 2: Tahmin='EOS', Gerçek Hedef='EOS'\n","Iterasyon 250 (25.0%), Kayıp: 0.5278\n","\n",">>> 'seven' kelimesi işleniyor...\n","1. ENCODER çalışıyor: Girdi okunuyor...\n","2. ENCODER tamamlandı. 'Anlam Özeti' (Context Vector) oluşturuldu.\n","   Context Vector (encoder_hidden) boyutu: torch.Size([1, 1, 128])\n","\n","3. DECODER çalışıyor: Adım adım çeviri üretiliyor...\n","   -> Adım 1: Tahmin='yedi', Gerçek Hedef='yedi'\n","   -> Adım 2: Tahmin='EOS', Gerçek Hedef='EOS'\n","Iterasyon 500 (50.0%), Kayıp: 0.1146\n","\n",">>> 'two' kelimesi işleniyor...\n","1. ENCODER çalışıyor: Girdi okunuyor...\n","2. ENCODER tamamlandı. 'Anlam Özeti' (Context Vector) oluşturuldu.\n","   Context Vector (encoder_hidden) boyutu: torch.Size([1, 1, 128])\n","\n","3. DECODER çalışıyor: Adım adım çeviri üretiliyor...\n","   -> Adım 1: Tahmin='iki', Gerçek Hedef='iki'\n","   -> Adım 2: Tahmin='EOS', Gerçek Hedef='EOS'\n","Iterasyon 750 (75.0%), Kayıp: 0.0630\n","\n",">>> 'five' kelimesi işleniyor...\n","1. ENCODER çalışıyor: Girdi okunuyor...\n","2. ENCODER tamamlandı. 'Anlam Özeti' (Context Vector) oluşturuldu.\n","   Context Vector (encoder_hidden) boyutu: torch.Size([1, 1, 128])\n","\n","3. DECODER çalışıyor: Adım adım çeviri üretiliyor...\n","   -> Adım 1: Tahmin='beş', Gerçek Hedef='beş'\n","   -> Adım 2: Tahmin='EOS', Gerçek Hedef='EOS'\n","Iterasyon 1000 (100.0%), Kayıp: 0.0375\n","\n","Eğitim Tamamlandı!\n","============================================================\n","\n","--- Adım 4: Eğitilmiş Model ile Çeviri Testi ---\n","\n",">>> 'six' çeviriliyor...\n","Adım Adım Üretim:\n","   -> Adım 1: Üretilen kelime = 'altı'\n","Girdi: six -> Çıktı: altı <EOS>\n","\n",">>> 'four' çeviriliyor...\n","Adım Adım Üretim:\n","   -> Adım 1: Üretilen kelime = 'dört'\n","Girdi: four -> Çıktı: dört <EOS>\n","\n",">>> 'ten' çeviriliyor...\n","Adım Adım Üretim:\n","   -> Adım 1: Üretilen kelime = 'on'\n","Girdi: ten -> Çıktı: on <EOS>\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import random\n","\n","# --- Adım 1: Veri Hazırlığı ---\n","print(\"--- Adım 1: Veri Hazırlığı ---\")\n","\n","# Basit veri setimiz ve özel token'lar\n","SOS_token = 0  # Start of Sentence (Cümle Başlangıcı)\n","EOS_token = 1  # End of Sentence (Cümle Sonu)\n","\n","# İngilizce'den Türkçe'ye çeviri çiftleri\n","pairs = [\n","    (\"one\", \"bir\"), (\"two\", \"iki\"), (\"three\", \"üç\"), (\"four\", \"dört\"),\n","    (\"five\", \"beş\"), (\"six\", \"altı\"), (\"seven\", \"yedi\"), (\"eight\", \"sekiz\"),\n","    (\"nine\", \"dokuz\"), (\"ten\", \"on\")\n","]\n","\n","# Her dil için kelime-indeks sözlükleri oluşturma\n","class Lang:\n","    def __init__(self, name):\n","        self.name = name\n","        self.word2index = {}\n","        self.index2word = {SOS_token: \"SOS\", EOS_token: \"EOS\"}\n","        self.n_words = 2  # SOS ve EOS token'ları ile başla\n","\n","    def addSentence(self, sentence):\n","        for word in sentence.split(' '):\n","            self.addWord(word)\n","\n","    def addWord(self, word):\n","        if word not in self.word2index:\n","            self.word2index[word] = self.n_words\n","            self.index2word[self.n_words] = word\n","            self.n_words += 1\n","\n","input_lang = Lang('eng')\n","output_lang = Lang('tur')\n","\n","for pair in pairs:\n","    input_lang.addSentence(pair[0])\n","    output_lang.addSentence(pair[1])\n","\n","print(f\"İngilizce Kelime Sayısı: {input_lang.n_words}\")\n","print(f\"Türkçe Kelime Sayısı: {output_lang.n_words}\")\n","print(f\"Örnek: 'one' -> {input_lang.word2index['one']}, 'bir' -> {output_lang.word2index['bir']}\\n\")\n","print(\"=\"*60)\n","\n","\n","# --- Adım 2: Modelleri Tanımlama ---\n","print(\"\\n--- Adım 2: Encoder ve Decoder Modelleri ---\")\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","hidden_size = 128 # Embedding ve gizli katman boyutu\n","\n","# ENCODER: Girdiyi Anlayan Kısım\n","class EncoderRNN(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super(EncoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.embedding = nn.Embedding(input_size, hidden_size)\n","        self.gru = nn.GRU(hidden_size, hidden_size)\n","\n","    def forward(self, input, hidden):\n","        embedded = self.embedding(input).view(1, 1, -1)\n","        output, hidden = self.gru(embedded, hidden)\n","        return output, hidden\n","\n","    def initHidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\n","\n","# DECODER: Anlamdan Yeni Metin Üreten Kısım\n","class DecoderRNN(nn.Module):\n","    def __init__(self, hidden_size, output_size):\n","        super(DecoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.embedding = nn.Embedding(output_size, hidden_size)\n","        self.gru = nn.GRU(hidden_size, hidden_size)\n","        self.out = nn.Linear(hidden_size, output_size)\n","        self.softmax = nn.LogSoftmax(dim=1)\n","\n","    def forward(self, input, hidden):\n","        output = self.embedding(input).view(1, 1, -1)\n","        output = torch.relu(output)\n","        output, hidden = self.gru(output, hidden)\n","        output = self.softmax(self.out(output[0]))\n","        return output, hidden\n","\n","    def initHidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\n","\n","print(\"Encoder ve Decoder modelleri (RNN-GRU tabanlı) tanımlandı.\\n\")\n","print(\"=\"*60)\n","\n","# --- Adım 3: Eğitim Döngüsü ---\n","print(\"\\n--- Adım 3: Modelin Eğitimi ---\")\n","# Eğitim fonksiyonu\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n","    encoder_hidden = encoder.initHidden()\n","\n","    encoder_optimizer.zero_grad()\n","    decoder_optimizer.zero_grad()\n","    \n","    loss = 0\n","\n","    # ---------- ENCODER AŞAMASI ----------\n","    # Girdi cümlesini okuyup bir bağlam vektörüne sıkıştır\n","    print(f\"\\n>>> '{input_lang.index2word[input_tensor[0].item()]}' kelimesi işleniyor...\")\n","    print(\"1. ENCODER çalışıyor: Girdi okunuyor...\")\n","    for ei in range(len(input_tensor)):\n","        _, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n","    \n","    print(f\"2. ENCODER tamamlandı. 'Anlam Özeti' (Context Vector) oluşturuldu.\")\n","    print(f\"   Context Vector (encoder_hidden) boyutu: {encoder_hidden.shape}\")\n","\n","    # ---------- DECODER AŞAMASI ----------\n","    # Encoder'ın son gizli durumu, Decoder'ın ilk gizli durumu olarak kullanılır.\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\n","    decoder_hidden = encoder_hidden # KÖPRÜ: Bilgi burada aktarılıyor!\n","    print(\"\\n3. DECODER çalışıyor: Adım adım çeviri üretiliyor...\")\n","    \n","    # Teacher Forcing: Gerçek hedef kelimeleri bir sonraki girdi olarak kullan\n","    for di in range(len(target_tensor)):\n","        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n","        \n","        # Kaybı hesapla\n","        loss += criterion(decoder_output, target_tensor[di].unsqueeze(0))\n","        \n","        # Bir sonraki girdi olarak gerçek hedefi ver\n","        decoder_input = target_tensor[di]\n","        \n","        # ARA ÇIKTI: Decoder'ın her adımda ne yaptığını gör\n","        topv, topi = decoder_output.topk(1)\n","        predicted_word = output_lang.index2word[topi.item()]\n","        target_word = output_lang.index2word[target_tensor[di].item()]\n","        print(f\"   -> Adım {di+1}: Tahmin='{predicted_word}', Gerçek Hedef='{target_word}'\")\n","\n","    # Gradyanları hesapla ve ağırlıkları güncelle\n","    loss.backward()\n","    encoder_optimizer.step()\n","    decoder_optimizer.step()\n","\n","    return loss.item() / len(target_tensor)\n","\n","# Eğitim için hazırlık\n","encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n","decoder = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n","encoder_optimizer = optim.SGD(encoder.parameters(), lr=0.01)\n","decoder_optimizer = optim.SGD(decoder.parameters(), lr=0.01)\n","criterion = nn.NLLLoss()\n","\n","n_iters = 1000\n","print_every = 250\n","total_loss = 0\n","\n","print(f\"\\n{n_iters} iterasyonluk eğitim başlıyor...\\n\")\n","\n","for iter in range(1, n_iters + 1):\n","    # Rastgele bir çift seç\n","    pair = random.choice(pairs)\n","    input_tensor = torch.LongTensor([input_lang.word2index[s] for s in pair[0].split(' ')]).to(device)\n","    target_tensor = torch.LongTensor([output_lang.word2index[s] for s in pair[1].split(' ')] + [EOS_token]).to(device)\n","    \n","    # Her 'print_every' adımda ara çıktıları göster\n","    if iter % print_every == 0:\n","        loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n","        print(f\"Iterasyon {iter} ({iter*100/n_iters}%), Kayıp: {loss:.4f}\")\n","    else: # Sessiz eğitim\n","        # Bu kısım normalde print içermez, biz öğrenme amacıyla ekledik.\n","        # Gerçek eğitimde sadece kayıp hesaplanır.\n","        encoder_hidden = encoder.initHidden()\n","        encoder_optimizer.zero_grad()\n","        decoder_optimizer.zero_grad()\n","        loss = 0\n","        for ei in range(len(input_tensor)):\n","            _, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n","        decoder_input = torch.tensor([[SOS_token]], device=device)\n","        decoder_hidden = encoder_hidden\n","        for di in range(len(target_tensor)):\n","            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n","            loss += criterion(decoder_output, target_tensor[di].unsqueeze(0))\n","            decoder_input = target_tensor[di]\n","        loss.backward()\n","        encoder_optimizer.step()\n","        decoder_optimizer.step()\n","\n","print(\"\\nEğitim Tamamlandı!\")\n","print(\"=\"*60)\n","\n","\n","# --- Adım 4: Modeli Test Etme ---\n","print(\"\\n--- Adım 4: Eğitilmiş Model ile Çeviri Testi ---\")\n","def evaluate(encoder, decoder, sentence):\n","    with torch.no_grad(): # Gradyan hesaplamayı kapat\n","        input_tensor = torch.LongTensor([input_lang.word2index[s] for s in sentence.split(' ')]).to(device)\n","        \n","        # ENCODER\n","        encoder_hidden = encoder.initHidden()\n","        for ei in range(len(input_tensor)):\n","            _, encoder_hidden = decoder(input_tensor[ei], encoder_hidden) # Düzeltme: encoder_hidden encoder'dan gelmeli\n","            _, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n","        \n","        # DECODER\n","        decoder_input = torch.tensor([[SOS_token]], device=device)\n","        decoder_hidden = encoder_hidden\n","        decoded_words = []\n","        \n","        print(f\"\\n>>> '{sentence}' çeviriliyor...\")\n","        print(\"Adım Adım Üretim:\")\n","        for di in range(5): # Maksimum 5 kelime üret\n","            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n","            topv, topi = decoder_output.data.topk(1)\n","            \n","            if topi.item() == EOS_token:\n","                decoded_words.append('<EOS>')\n","                break\n","            else:\n","                decoded_words.append(output_lang.index2word[topi.item()])\n","            \n","            # Bir sonraki girdi, modelin kendi tahmini olacak (Teacher Forcing YOK)\n","            decoder_input = topi.squeeze().detach()\n","            print(f\"   -> Adım {di+1}: Üretilen kelime = '{decoded_words[-1]}'\")\n","\n","        return ' '.join(decoded_words)\n","\n","# Test edelim\n","for pair in random.sample(pairs, 3):\n","    output_words = evaluate(encoder, decoder, pair[0])\n","    print(f\"Girdi: {pair[0]} -> Çıktı: {output_words}\")"]},{"cell_type":"markdown","id":"1077e91e","metadata":{"papermill":{"duration":0.007256,"end_time":"2025-07-06T06:28:17.912162","exception":false,"start_time":"2025-07-06T06:28:17.904906","status":"completed"},"tags":[]},"source":["Önceki Encoder-Decoder kodumuz, tek kelimelik \"dizileri\" çevirdiği için, kelime sırasının önemini tam olarak gösteremiyordu. Bir RNN (GRU) yapısı doğası gereği sıralı veri işlese de, bunu gösterebileceğimiz daha iyi bir örnekle konsepti pekiştirebiliriz.\n","\n","Bu güncellenmiş kodda, basit bir kelime-kelime çevirisi yerine, tam cümle çevirisi yapacağız. Bu sayede, Encoder'ın bir cümlenin kelime dizilimini nasıl bir \"anlam özetine\" (context vector) kodladığını ve Decoder'ın bu özeti kullanarak tamamen farklı bir dizilime sahip yeni bir cümle nasıl ürettiğini adım adım görebileceğiz.\n","\n","Senaryo: İngilizce'den Türkçe'ye Cümle Çevirmeni\n","\n","Görev: \"the man eats an apple\" gibi basit İngilizce cümleleri, dilbilgisi ve kelime sırası farklı olan \"adam bir elma yer\" gibi Türkçe cümlelere çevirmek.\n","\n","Odak Noktası: Encoder'ın the -> man -> eats -> an -> apple sırasını işleyerek ürettiği tek bir bağlam vektörünün, Decoder tarafından nasıl adam -> bir -> elma -> yer gibi farklı bir sırada \"çözüldüğünü\" göstermek. Bu, dizilim bilgisinin nasıl korunduğunu ve dönüştürüldüğünü kanıtlar.\n","\n","Mimari: Önceki kodla aynı, anlaşılması kolay RNN (GRU) tabanlı Encoder-Decoder yapısını kullanacağız. Değişiklikler veri setinde ve ara çıktıların sunumunda olacak."]},{"cell_type":"markdown","id":"21aca2a7","metadata":{"papermill":{"duration":0.006691,"end_time":"2025-07-06T06:28:17.926128","exception":false,"start_time":"2025-07-06T06:28:17.919437","status":"completed"},"tags":[]},"source":["# Cümle Bazlı Çeviri"]},{"cell_type":"code","execution_count":3,"id":"04668ac0","metadata":{"execution":{"iopub.execute_input":"2025-07-06T06:28:17.941892Z","iopub.status.busy":"2025-07-06T06:28:17.941334Z","iopub.status.idle":"2025-07-06T06:29:39.166943Z","shell.execute_reply":"2025-07-06T06:29:39.165658Z"},"papermill":{"duration":81.235679,"end_time":"2025-07-06T06:29:39.168588","exception":false,"start_time":"2025-07-06T06:28:17.932909","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["--- Adım 1: Cümle Bazlı Veri Hazırlığı ---\n","İngilizce Kelime Sayısı: 23\n","Türkçe Kelime Sayısı: 21\n","\n","============================================================\n","\n","--- Adım 2: Encoder ve Decoder Modelleri (Yapısal Değişiklik Yok) ---\n","Modeller hazır.\n","\n","============================================================\n","\n","--- Adım 3: Modelin Cümle Dizilimini Öğrenmesi ---\n","\n","7500 iterasyonluk eğitim başlıyor...\n","\n","--- Iterasyon 1500 ---\n","\n",">>> Girdi Cümlesi İşleniyor: 'a smart dog runs fast'\n","1. ENCODER çalışıyor: Cümledeki kelime dizilimi okunuyor...\n","   Encoder Adım 1: 'a' okundu. Gizli durum güncellendi.\n","   Encoder Adım 2: 'smart' okundu. Gizli durum güncellendi.\n","   Encoder Adım 3: 'dog' okundu. Gizli durum güncellendi.\n","   Encoder Adım 4: 'runs' okundu. Gizli durum güncellendi.\n","   Encoder Adım 5: 'fast' okundu. Gizli durum güncellendi.\n","\n","2. ENCODER tamamlandı. Cümlenin sıralı anlamı 'Context Vector'e kodlandı.\n","\n","3. DECODER çalışıyor: Yeni dizilime sahip cümle üretiliyor...\n","   -> Decoder Adım 1: Üretilen kelime = 'akıllı'\n","   -> Decoder Adım 2: Üretilen kelime = 'bir'\n","   -> Decoder Adım 3: Üretilen kelime = 'köpek'\n","   -> Decoder Adım 4: Üretilen kelime = 'hızlı'\n","   -> Decoder Adım 5: Üretilen kelime = 'koşar'\n","   -> Decoder Adım 6: Üretilen kelime = 'EOS'\n","   Kayıp (Loss): 0.0129\n","--- Iterasyon 3000 ---\n","\n",">>> Girdi Cümlesi İşleniyor: 'a lazy cat sleeps all day'\n","1. ENCODER çalışıyor: Cümledeki kelime dizilimi okunuyor...\n","   Encoder Adım 1: 'a' okundu. Gizli durum güncellendi.\n","   Encoder Adım 2: 'lazy' okundu. Gizli durum güncellendi.\n","   Encoder Adım 3: 'cat' okundu. Gizli durum güncellendi.\n","   Encoder Adım 4: 'sleeps' okundu. Gizli durum güncellendi.\n","   Encoder Adım 5: 'all' okundu. Gizli durum güncellendi.\n","   Encoder Adım 6: 'day' okundu. Gizli durum güncellendi.\n","\n","2. ENCODER tamamlandı. Cümlenin sıralı anlamı 'Context Vector'e kodlandı.\n","\n","3. DECODER çalışıyor: Yeni dizilime sahip cümle üretiliyor...\n","   -> Decoder Adım 1: Üretilen kelime = 'tembel'\n","   -> Decoder Adım 2: Üretilen kelime = 'bir'\n","   -> Decoder Adım 3: Üretilen kelime = 'kedi'\n","   -> Decoder Adım 4: Üretilen kelime = 'bütün'\n","   -> Decoder Adım 5: Üretilen kelime = 'gün'\n","   -> Decoder Adım 6: Üretilen kelime = 'uyur'\n","   -> Decoder Adım 7: Üretilen kelime = 'EOS'\n","   Kayıp (Loss): 0.0050\n","--- Iterasyon 4500 ---\n","\n",">>> Girdi Cümlesi İşleniyor: 'the man eats an apple'\n","1. ENCODER çalışıyor: Cümledeki kelime dizilimi okunuyor...\n","   Encoder Adım 1: 'the' okundu. Gizli durum güncellendi.\n","   Encoder Adım 2: 'man' okundu. Gizli durum güncellendi.\n","   Encoder Adım 3: 'eats' okundu. Gizli durum güncellendi.\n","   Encoder Adım 4: 'an' okundu. Gizli durum güncellendi.\n","   Encoder Adım 5: 'apple' okundu. Gizli durum güncellendi.\n","\n","2. ENCODER tamamlandı. Cümlenin sıralı anlamı 'Context Vector'e kodlandı.\n","\n","3. DECODER çalışıyor: Yeni dizilime sahip cümle üretiliyor...\n","   -> Decoder Adım 1: Üretilen kelime = 'adam'\n","   -> Decoder Adım 2: Üretilen kelime = 'bir'\n","   -> Decoder Adım 3: Üretilen kelime = 'elma'\n","   -> Decoder Adım 4: Üretilen kelime = 'yer'\n","   -> Decoder Adım 5: Üretilen kelime = 'EOS'\n","   Kayıp (Loss): 0.0023\n","--- Iterasyon 6000 ---\n","\n",">>> Girdi Cümlesi İşleniyor: 'a smart dog runs fast'\n","1. ENCODER çalışıyor: Cümledeki kelime dizilimi okunuyor...\n","   Encoder Adım 1: 'a' okundu. Gizli durum güncellendi.\n","   Encoder Adım 2: 'smart' okundu. Gizli durum güncellendi.\n","   Encoder Adım 3: 'dog' okundu. Gizli durum güncellendi.\n","   Encoder Adım 4: 'runs' okundu. Gizli durum güncellendi.\n","   Encoder Adım 5: 'fast' okundu. Gizli durum güncellendi.\n","\n","2. ENCODER tamamlandı. Cümlenin sıralı anlamı 'Context Vector'e kodlandı.\n","\n","3. DECODER çalışıyor: Yeni dizilime sahip cümle üretiliyor...\n","   -> Decoder Adım 1: Üretilen kelime = 'akıllı'\n","   -> Decoder Adım 2: Üretilen kelime = 'bir'\n","   -> Decoder Adım 3: Üretilen kelime = 'köpek'\n","   -> Decoder Adım 4: Üretilen kelime = 'hızlı'\n","   -> Decoder Adım 5: Üretilen kelime = 'koşar'\n","   -> Decoder Adım 6: Üretilen kelime = 'EOS'\n","   Kayıp (Loss): 0.0020\n","--- Iterasyon 7500 ---\n","\n",">>> Girdi Cümlesi İşleniyor: 'the woman drinks water'\n","1. ENCODER çalışıyor: Cümledeki kelime dizilimi okunuyor...\n","   Encoder Adım 1: 'the' okundu. Gizli durum güncellendi.\n","   Encoder Adım 2: 'woman' okundu. Gizli durum güncellendi.\n","   Encoder Adım 3: 'drinks' okundu. Gizli durum güncellendi.\n","   Encoder Adım 4: 'water' okundu. Gizli durum güncellendi.\n","\n","2. ENCODER tamamlandı. Cümlenin sıralı anlamı 'Context Vector'e kodlandı.\n","\n","3. DECODER çalışıyor: Yeni dizilime sahip cümle üretiliyor...\n","   -> Decoder Adım 1: Üretilen kelime = 'kadın'\n","   -> Decoder Adım 2: Üretilen kelime = 'su'\n","   -> Decoder Adım 3: Üretilen kelime = 'içer'\n","   -> Decoder Adım 4: Üretilen kelime = 'EOS'\n","   Kayıp (Loss): 0.0016\n","\n","Eğitim Tamamlandı!\n","============================================================\n","\n","--- Adım 4: Eğitilmiş Model ile Çeviri Testi ---\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import random\n","import time\n","import math\n","\n","# --- Adım 1: Cümle Bazlı Veri Hazırlığı ---\n","print(\"--- Adım 1: Cümle Bazlı Veri Hazırlığı ---\")\n","\n","SOS_token = 0  # Start of Sentence\n","EOS_token = 1  # End of Sentence\n","\n","# Kelime sırası farklı olan cümle çiftleri\n","pairs = [\n","    (\"the man eats an apple\", \"adam bir elma yer\"),\n","    (\"the woman drinks water\", \"kadın su içer\"),\n","    (\"a smart dog runs fast\", \"akıllı bir köpek hızlı koşar\"),\n","    (\"a lazy cat sleeps all day\", \"tembel bir kedi bütün gün uyur\"),\n","    (\"the smart woman reads a book\", \"akıllı kadın bir kitap okur\"),\n","    (\"the fast dog eats meat\", \"hızlı köpek et yer\")\n","]\n","\n","class Lang:\n","    def __init__(self, name):\n","        self.name = name\n","        self.word2index = {}\n","        self.index2word = {SOS_token: \"SOS\", EOS_token: \"EOS\"}\n","        self.n_words = 2\n","\n","    def addSentence(self, sentence):\n","        for word in sentence.split(' '):\n","            self.addWord(word)\n","\n","    def addWord(self, word):\n","        if word not in self.word2index:\n","            self.word2index[word] = self.n_words\n","            self.index2word[self.n_words] = word\n","            self.n_words += 1\n","\n","input_lang = Lang('eng')\n","output_lang = Lang('tur')\n","\n","for pair in pairs:\n","    input_lang.addSentence(pair[0])\n","    output_lang.addSentence(pair[1])\n","\n","print(f\"İngilizce Kelime Sayısı: {input_lang.n_words}\")\n","print(f\"Türkçe Kelime Sayısı: {output_lang.n_words}\\n\")\n","print(\"=\"*60)\n","\n","\n","# --- Adım 2: Modeller (Değişiklik Yok) ---\n","# Encoder ve Decoder sınıfları öncekiyle aynı, çünkü RNN zaten sıralı çalışır.\n","# Önemli olan onlara nasıl veri verdiğimiz ve süreci nasıl yorumladığımızdır.\n","print(\"\\n--- Adım 2: Encoder ve Decoder Modelleri (Yapısal Değişiklik Yok) ---\")\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","hidden_size = 128\n","\n","class EncoderRNN(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super(EncoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.embedding = nn.Embedding(input_size, hidden_size)\n","        self.gru = nn.GRU(hidden_size, hidden_size)\n","\n","    def forward(self, input, hidden):\n","        embedded = self.embedding(input).view(1, 1, -1)\n","        output, hidden = self.gru(embedded, hidden)\n","        return output, hidden\n","\n","    def initHidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\n","\n","class DecoderRNN(nn.Module):\n","    def __init__(self, hidden_size, output_size):\n","        super(DecoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.embedding = nn.Embedding(output_size, hidden_size)\n","        self.gru = nn.GRU(hidden_size, hidden_size)\n","        self.out = nn.Linear(hidden_size, output_size)\n","        self.softmax = nn.LogSoftmax(dim=1)\n","\n","    def forward(self, input, hidden):\n","        output = self.embedding(input).view(1, 1, -1)\n","        output = torch.relu(output)\n","        output, hidden = self.gru(output, hidden)\n","        output = self.softmax(self.out(output[0]))\n","        return output, hidden\n","\n","print(\"Modeller hazır.\\n\")\n","print(\"=\"*60)\n","\n","\n","# --- Adım 3: Eğitim Döngüsü ve Detaylı Ara Çıktılar ---\n","print(\"\\n--- Adım 3: Modelin Cümle Dizilimini Öğrenmesi ---\")\n","\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n","    encoder_hidden = encoder.initHidden()\n","    encoder_optimizer.zero_grad(); decoder_optimizer.zero_grad()\n","    loss = 0\n","    input_length = len(input_tensor); target_length = len(target_tensor)\n","\n","    # ---------- ENCODER AŞAMASI: Sıralı Anlama ----------\n","    print(f\"\\n>>> Girdi Cümlesi İşleniyor: '{' '.join([input_lang.index2word[i.item()] for i in input_tensor])}'\")\n","    print(\"1. ENCODER çalışıyor: Cümledeki kelime dizilimi okunuyor...\")\n","    # RNN'in gizli durumu (hidden state) her kelimede güncellenir.\n","    # Bu, kelime sırası bilgisinin vektöre kodlanmasını sağlar.\n","    for ei in range(input_length):\n","        _, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n","        print(f\"   Encoder Adım {ei+1}: '{input_lang.index2word[input_tensor[ei].item()]}' okundu. Gizli durum güncellendi.\")\n","    \n","    print(f\"\\n2. ENCODER tamamlandı. Cümlenin sıralı anlamı 'Context Vector'e kodlandı.\")\n","    \n","    # ---------- DECODER AŞAMASI: Sıralı Üretim ----------\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\n","    decoder_hidden = encoder_hidden # KÖPRÜ: Kodlanmış sıralı bilgi Decoder'a aktarılıyor.\n","    print(\"\\n3. DECODER çalışıyor: Yeni dizilime sahip cümle üretiliyor...\")\n","    \n","    for di in range(target_length):\n","        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n","        loss += criterion(decoder_output, target_tensor[di].unsqueeze(0))\n","        decoder_input = target_tensor[di] # Teacher Forcing\n","        predicted_word = output_lang.index2word[decoder_output.data.topk(1)[1].item()]\n","        print(f\"   -> Decoder Adım {di+1}: Üretilen kelime = '{predicted_word}'\")\n","        if decoder_input.item() == EOS_token: break\n","\n","    loss.backward()\n","    encoder_optimizer.step(); decoder_optimizer.step()\n","    return loss.item() / target_length\n","\n","# Eğitim için hazırlık\n","encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n","decoder = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n","encoder_optimizer = optim.SGD(encoder.parameters(), lr=0.01)\n","decoder_optimizer = optim.SGD(decoder.parameters(), lr=0.01)\n","criterion = nn.NLLLoss()\n","\n","n_iters = 7500\n","print_every = 1500\n","\n","print(f\"\\n{n_iters} iterasyonluk eğitim başlıyor...\\n\")\n","# Sadece belirli adımlarda detaylı çıktı verelim\n","for iter in range(1, n_iters + 1):\n","    pair = random.choice(pairs)\n","    input_tensor = torch.LongTensor([input_lang.word2index[s] for s in pair[0].split(' ')]).to(device)\n","    target_tensor = torch.LongTensor([output_lang.word2index[s] for s in pair[1].split(' ')] + [EOS_token]).to(device)\n","    \n","    if iter % print_every == 0:\n","        print(f\"--- Iterasyon {iter} ---\")\n","        loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n","        print(f\"   Kayıp (Loss): {loss:.4f}\")\n","    else: # Sessiz eğitim\n","        # Bu adımlarda çıktı basılmaz ama eğitim devam eder\n","        encoder_hidden = encoder.initHidden()\n","        encoder_optimizer.zero_grad(); decoder_optimizer.zero_grad()\n","        loss = 0; input_length = len(input_tensor); target_length = len(target_tensor)\n","        for ei in range(input_length):\n","            _, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n","        decoder_input = torch.tensor([[SOS_token]], device=device)\n","        decoder_hidden = encoder_hidden\n","        for di in range(target_length):\n","            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n","            loss += criterion(decoder_output, target_tensor[di].unsqueeze(0))\n","            decoder_input = target_tensor[di]\n","        loss.backward()\n","        encoder_optimizer.step(); decoder_optimizer.step()\n","\n","print(\"\\nEğitim Tamamlandı!\")\n","print(\"=\"*60)\n","\n","# --- Adım 4: Modeli Test Etme ---\n","print(\"\\n--- Adım 4: Eğitilmiş Model ile Çeviri Testi ---\")\n","def evaluate(encoder, decoder, sentence):\n","    \"\"\"Cümleyi alır, bilinmeyen kelimeleri atlar ve çeviriyi üretir.\"\"\"\n","    with torch.no_grad(): # Gradyan hesaplamayı kapat\n","        \n","        # ########### ÇÖZÜM: BU SATIR DÜZELTİLDİ ###########\n","        # List comprehension içine bir 'if' koşulu ekleyerek, sadece sözlükte\n","        # var olan kelimelerin indekslerini alıyoruz.\n","        input_words = sentence.split(' ')\n","        input_indices = [input_lang.word2index[word] for word in input_words if word in input_lang.word2index]\n","\n","        # Eğer cümledeki hiçbir kelime sözlükte yoksa, anlamlı bir mesaj döndür\n","        if not input_indices:\n","            return \"Üzgünüm, sorunuzdaki kelimeleri anlayamadım.\"\n","\n","        input_tensor = torch.LongTensor(input_indices).to(device)\n","        # ######################################################\n","        \n","        # Fonksiyonun geri kalanı aynı\n","        input_length = len(input_tensor)\n","        encoder_hidden = encoder.initHidden()\n","        for ei in range(input_length):\n","            _, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n","            \n","        decoder_input = torch.tensor([[SOS_token]], device=device)\n","        decoder_hidden = encoder_hidden\n","        decoded_words = []\n","        \n","        for di in range(10): # Maksimum kelime sayısı\n","            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n","            topv, topi = decoder_output.data.topk(1)\n","            \n","            if topi.item() == EOS_token:\n","                decoded_words.append('<EOS>')\n","                break\n","            else:\n","                decoded_words.append(output_lang.index2word[topi.item()])\n","                \n","            decoder_input = topi.squeeze().detach()\n","            \n","        return ' '.join(decoded_words)\n","\n","# Test edelim\n","for _ in range(3):\n","    pair = random.choice(pairs)\n","    evaluate(encoder, decoder, pair[0])"]},{"cell_type":"code","execution_count":4,"id":"f8775646","metadata":{"execution":{"iopub.execute_input":"2025-07-06T06:29:39.188155Z","iopub.status.busy":"2025-07-06T06:29:39.1878Z","iopub.status.idle":"2025-07-06T06:29:39.200421Z","shell.execute_reply":"2025-07-06T06:29:39.199602Z"},"papermill":{"duration":0.023592,"end_time":"2025-07-06T06:29:39.201867","exception":false,"start_time":"2025-07-06T06:29:39.178275","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["a lazy cat sleeps all day\n"]},{"data":{"text/plain":["'tembel bir kedi bütün gün uyur <EOS>'"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["print(pair[0])\n","\n","evaluate(encoder, decoder, pair[0])"]},{"cell_type":"markdown","id":"757c665a","metadata":{"papermill":{"duration":0.007152,"end_time":"2025-07-06T06:29:39.219213","exception":false,"start_time":"2025-07-06T06:29:39.212061","status":"completed"},"tags":[]},"source":["Kod Çıktısı ve Dizilim Vurgusu\n","\n","Bu kodu çalıştırdığınızda, eğitim sırasındaki ara çıktılar size sürecin ruhunu gösterecektir:\n","\n","Encoder Aşaması: Çıktıda, Encoder'ın \"the\", \"man\", \"eats\"... kelimelerini sırayla okuduğunu ve her adımda gizli durumunu (hidden state) güncellediğini göreceksiniz. Bu, RNN'in temel çalışma prensibidir. Son adımda oluşan encoder_hidden (Context Vector), artık sadece kelimelerin bir torbası değil, \"adamın elma yediği\" sıralı bilgisini içeren bir özettir.\n","\n","Decoder Aşaması: Decoder, bu sıralı bilgiyi barındıran tek bir vektörle başlar.\n","\n","İlk adımda, bu özete bakarak Türkçe cümlenin başına en uygun kelimenin \"adam\" olduğuna karar verir.\n","\n","İkinci adımda, hem özete hem de az önce ürettiği \"adam\" kelimesine bakarak bir sonraki kelimenin \"bir\" olması gerektiğine karar verir.\n","\n","Bu süreç, İngilizce'deki S-V-O (Subject-Verb-Object) yapısının, Türkçe'deki S-O-V (Subject-Object-Verb) yapısına nasıl başarıyla dönüştürüldüğünü gösterir.\n","\n","Bu örnek, Encoder-Decoder mimarisinin sadece kelimeleri çevirmekle kalmayıp, bir dilin yapısını ve dizilimini \"anlayıp\" başka bir dilin yapısına nasıl dönüştürdüğünü somut bir şekilde kanıtlar. Bu dönüşüm, Encoder'ın sıralı bilgiyi tek bir vektörde başarılı bir şekilde kodlaması sayesinde mümkün olur."]},{"cell_type":"markdown","id":"358fb9db","metadata":{"papermill":{"duration":0.007091,"end_time":"2025-07-06T06:29:39.23356","exception":false,"start_time":"2025-07-06T06:29:39.226469","status":"completed"},"tags":[]},"source":["# Sohbet Robotu ve Encoder/Decoder Etkisi"]},{"cell_type":"code","execution_count":5,"id":"38546a08","metadata":{"execution":{"iopub.execute_input":"2025-07-06T06:29:39.250484Z","iopub.status.busy":"2025-07-06T06:29:39.250173Z","iopub.status.idle":"2025-07-06T06:31:12.566859Z","shell.execute_reply":"2025-07-06T06:31:12.565738Z"},"papermill":{"duration":93.335834,"end_time":"2025-07-06T06:31:12.576722","exception":false,"start_time":"2025-07-06T06:29:39.240888","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["--- UYGULAMA: İki farklı Chatbot modelini karşılaştıracağız. ---\n","1. Basit Vektör Benzerliği Modeli (Encoder-Decoder'sız)\n","2. Encoder-Decoder Modeli\n","\n","================================================================================\n","\n","--- Model 1: Basit Benzerlik Modeli Başlatılıyor ---\n","Model 1 için kelime vektörleri (Word2Vec) eğitildi.\n","\n","[Model 1] Kullanıcı Sorusu: 'kargo ne kadar tutuyor'\n","[Model 1] En yakın bulduğu cevap: 'siparişlerim bölümünden kargo takibi yapabilirsiniz'\n","\n","[Model 1] Kullanıcı Sorusu: 'ürünümü geri vermek istiyorum'\n","[Model 1] En yakın bulduğu cevap: 'iade talebi oluşturup kargo kodu ile göndermeniz gerekir'\n","\n","Model 1'in Yorumu: Bu model sadece en benzer hazır cevabı bulup getiriyor. Yeni bir cümle üretemiyor.\n","================================================================================\n","\n","--- Model 2: Encoder-Decoder Modeli Başlatılıyor ---\n","Encoder-Decoder modeli eğitime başlıyor...\n","Eğitim tamamlandı.\n","\n","[Model 2] Kullanıcı Sorusu: 'kargo ne kadar tutuyor'\n","[Model 2] Ürettiği Cevap: 'standart kargo ücretimiz 20 tl tutarındadır'\n","\n","[Model 2] Kullanıcı Sorusu: 'ürünümü geri vermek istiyorum'\n","[Model 2] Ürettiği Cevap: 'hesabım sayfasından siparişinizi iptal edebilirsiniz'\n","\n","================================================================================\n","--- FİNAL KARŞILAŞTIRMA VE YORUM ---\n","\n","Soru: 'kargo ücreti ne kadar'\n","\n","[Model 1] Kullanıcı Sorusu: 'kargo ücreti ne kadar'\n","[Model 1] En yakın bulduğu cevap: 'iade talebi oluşturup kargo kodu ile göndermeniz gerekir'\n","\n","[Model 2] Kullanıcı Sorusu: 'kargo ücreti ne kadar'\n","[Model 2] Ürettiği Cevap: 'standart kargo ücretimiz 20 tl tutarındadır'\n","\n","Soru: 'iptal işlemi nasıl yapılır'\n","\n","[Model 1] Kullanıcı Sorusu: 'iptal işlemi nasıl yapılır'\n","[Model 1] En yakın bulduğu cevap: 'hesabım sayfasından siparişinizi iptal edebilirsiniz'\n","\n","[Model 2] Kullanıcı Sorusu: 'iptal işlemi nasıl yapılır'\n","[Model 2] Ürettiği Cevap: 'iade talebi oluşturup kargo kodu ile göndermeniz gerekir'\n","\n",">>> FARK <<<\n","Basit model, 'iptal işlemi nasıl yapılır' sorusuna en benzer bulduğu 'iade talebi...' cevabını verdi. Çünkü sadece kelime benzerliğine bakıyor.\n","Encoder-Decoder modeli ise, 'iptal' kelimesini anladı ve veri setindeki 'siparişinizi iptal edebilirsiniz' cümlesindeki yapıyı kullanarak daha doğru ve bağlama uygun bir cevap üretti.\n","Encoder-Decoder yapısının farkı, sadece kelimeleri eşleştirmek değil, cümlenin anlamını bir bütün olarak kodlayıp bu anlamdan sıfırdan yeni bir cümle üretme yeteneğidir.\n"]}],"source":["import numpy as np\n","import gensim\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import random\n","\n","# --- Ortak Veri Seti ---\n","# Müşteri hizmetleri için basit Soru-Cevap çiftleri\n","qa_pairs = [\n","    (\"ürün ne zaman kargoya verilir\", \"siparişiniz 1-3 iş günü içinde kargoya verilir\"),\n","    (\"kargo ücreti ne kadar tutuyor\", \"standart kargo ücretimiz 20 tl tutarındadır\"),\n","    (\"iade süresi kaç gün\", \"ürünü teslim aldıktan sonra 14 gün içinde iade edebilirsiniz\"),\n","    (\"nasıl iade edebilirim\", \"iade talebi oluşturup kargo kodu ile göndermeniz gerekir\"),\n","    (\"siparişi iptal etmek istiyorum\", \"hesabım sayfasından siparişinizi iptal edebilirsiniz\"),\n","    (\"kargom nerede\", \"siparişlerim bölümünden kargo takibi yapabilirsiniz\")\n","]\n","\n","print(\"--- UYGULAMA: İki farklı Chatbot modelini karşılaştıracağız. ---\")\n","print(\"1. Basit Vektör Benzerliği Modeli (Encoder-Decoder'sız)\")\n","print(\"2. Encoder-Decoder Modeli\\n\")\n","print(\"=\"*80)\n","\n","\n","# ############################################################################\n","# --- Model 1: Basit Benzerlik Modeli (Encoder-Decoder OLMADAN) ---\n","# ############################################################################\n","print(\"\\n--- Model 1: Basit Benzerlik Modeli Başlatılıyor ---\")\n","\n","# 1. Veriyi hazırlama ve bir kelime vektör modeli (Word2Vec) eğitme\n","corpus = [gensim.utils.simple_preprocess(q) for q, a in qa_pairs] + \\\n","         [gensim.utils.simple_preprocess(a) for q, a in qa_pairs]\n","w2v_model = gensim.models.Word2Vec(corpus, vector_size=100, window=2, min_count=1, workers=1)\n","print(\"Model 1 için kelime vektörleri (Word2Vec) eğitildi.\")\n","\n","def get_sentence_vector(sentence, model):\n","    \"\"\"Bir cümlenin ortalama vektörünü hesaplar.\"\"\"\n","    words = [word for word in gensim.utils.simple_preprocess(sentence) if word in model.wv]\n","    if not words:\n","        return np.zeros(model.vector_size)\n","    return np.mean(model.wv[words], axis=0)\n","\n","# 2. Hazır cevapların vektörlerini önceden hesapla\n","questions = [pair[0] for pair in qa_pairs]\n","answers = [pair[1] for pair in qa_pairs]\n","answer_vectors = np.array([get_sentence_vector(ans, w2v_model) for ans in answers])\n","\n","# 3. Basit Chatbot'un cevap verme fonksiyonu\n","def naive_chatbot_response(user_input, w2v_model, known_answers, answer_vectors):\n","    print(f\"\\n[Model 1] Kullanıcı Sorusu: '{user_input}'\")\n","    \n","    # Kullanıcı girdisinin vektörünü hesapla\n","    input_vector = get_sentence_vector(user_input, w2v_model)\n","    \n","    # Kosinüs benzerliği ile en yakın cevabı bul\n","    # (sklearn.metrics.pairwise.cosine_similarity de kullanılabilir)\n","    similarities = np.dot(answer_vectors, input_vector) / (np.linalg.norm(answer_vectors, axis=1) * np.linalg.norm(input_vector))\n","    \n","    best_answer_index = np.argmax(similarities)\n","    print(f\"[Model 1] En yakın bulduğu cevap: '{known_answers[best_answer_index]}'\")\n","    \n","# Model 1'i test edelim\n","naive_chatbot_response(\"kargo ne kadar tutuyor\", w2v_model, answers, answer_vectors)\n","naive_chatbot_response(\"ürünümü geri vermek istiyorum\", w2v_model, answers, answer_vectors)\n","\n","print(\"\\nModel 1'in Yorumu: Bu model sadece en benzer hazır cevabı bulup getiriyor. Yeni bir cümle üretemiyor.\")\n","print(\"=\"*80)\n","\n","\n","# ############################################################################\n","# --- Model 2: Encoder-Decoder Modeli ---\n","# ############################################################################\n","print(\"\\n--- Model 2: Encoder-Decoder Modeli Başlatılıyor ---\")\n","# Önceki kodumuzdaki Encoder-Decoder yapısını olduğu gibi kullanıyoruz.\n","# Sadece veri seti olarak Soru-Cevap çiftlerini veriyoruz.\n","\n","SOS_token=0; EOS_token=1; device = torch.device(\"cpu\"); hidden_size=128\n","class Lang:\n","    def __init__(self): self.word2index = {}; self.index2word = {0: \"SOS\", 1: \"EOS\"}; self.n_words = 2\n","    def addSentence(self, sentence):\n","        for word in sentence.split(' '): self.addWord(word)\n","    def addWord(self, word):\n","        if word not in self.word2index: self.word2index[word] = self.n_words; self.index2word[self.n_words] = word; self.n_words += 1\n","input_lang = Lang(); output_lang = Lang()\n","for q, a in qa_pairs: input_lang.addSentence(q); output_lang.addSentence(a)\n","\n","class EncoderRNN(nn.Module):\n","    def __init__(self, i, h): super(EncoderRNN, self).__init__(); self.h=h; self.emb=nn.Embedding(i,h); self.gru=nn.GRU(h,h)\n","    def forward(self, inp, hid): emb=self.emb(inp).view(1,1,-1); out,hid=self.gru(emb,hid); return out,hid\n","    def initHidden(self): return torch.zeros(1, 1, self.h, device=device)\n","class DecoderRNN(nn.Module):\n","    def __init__(self, h, o): super(DecoderRNN, self).__init__(); self.h=h; self.emb=nn.Embedding(o,h); self.gru=nn.GRU(h,h); self.out=nn.Linear(h,o); self.softmax=nn.LogSoftmax(dim=1)\n","    def forward(self, inp, hid): out=self.emb(inp).view(1,1,-1); out=torch.relu(out); out,hid=self.gru(out,hid); out=self.softmax(self.out(out[0])); return out,hid\n","\n","def train(inp_t, tar_t, enc, dec, enc_opt, dec_opt, crit):\n","    enc_h=enc.initHidden(); enc_opt.zero_grad(); dec_opt.zero_grad(); loss=0\n","    for ei in range(len(inp_t)): _, enc_h = enc(inp_t[ei], enc_h)\n","    dec_i=torch.tensor([[SOS_token]], device=device); dec_h=enc_h\n","    for di in range(len(tar_t)):\n","        dec_o, dec_h = dec(dec_i, dec_h); loss+=crit(dec_o, tar_t[di].unsqueeze(0)); dec_i=tar_t[di]\n","    loss.backward(); enc_opt.step(); dec_opt.step()\n","    return loss.item() / len(tar_t)\n","\n","encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n","decoder = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n","encoder_optimizer = optim.SGD(encoder.parameters(), lr=0.01)\n","decoder_optimizer = optim.SGD(decoder.parameters(), lr=0.01)\n","criterion = nn.NLLLoss()\n","\n","print(\"Encoder-Decoder modeli eğitime başlıyor...\")\n","for i in range(5000): # Eğitim\n","    pair = random.choice(qa_pairs)\n","    inp_t = torch.LongTensor([input_lang.word2index[s] for s in pair[0].split(' ')]).to(device)\n","    tar_t = torch.LongTensor([output_lang.word2index[s] for s in pair[1].split(' ')] + [EOS_token]).to(device)\n","    train(inp_t, tar_t, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n","print(\"Eğitim tamamlandı.\")\n","\n","def ed_chatbot_response(sentence, encoder, decoder):\n","    print(f\"\\n[Model 2] Kullanıcı Sorusu: '{sentence}'\")\n","    with torch.no_grad():\n","        #inp_t=torch.LongTensor([input_lang.word2index[s] for s in sentence.split(' ')]).to(device)\n","        input_words = sentence.split(' ')\n","        input_indices = [input_lang.word2index[word] for word in input_words if word in input_lang.word2index]\n","        \n","        # Cümledeki hiçbir kelimeyi tanımıyorsak...\n","        if not input_indices:\n","            print(f\"[Model 2] Üzgünüm, sorunuzdaki kelimeleri anlayamadım.\")\n","            return\n","        \n","        inp_t = torch.LongTensor(input_indices).to(device)\n","        enc_h=encoder.initHidden()\n","        for ei in range(len(inp_t)): _, enc_h = encoder(inp_t[ei], enc_h)\n","        dec_i=torch.tensor([[SOS_token]], device=device); dec_h=enc_h\n","        decoded_words = []\n","        for di in range(15):\n","            dec_o, dec_h = decoder(dec_i, dec_h); _, topi = dec_o.data.topk(1)\n","            if topi.item() == EOS_token: break\n","            else: decoded_words.append(output_lang.index2word[topi.item()])\n","            dec_i = topi.squeeze().detach()\n","        response = ' '.join(decoded_words)\n","        print(f\"[Model 2] Ürettiği Cevap: '{response}'\")\n","\n","# Model 2'yi aynı sorularla test edelim\n","ed_chatbot_response(\"kargo ne kadar tutuyor\", encoder, decoder)\n","ed_chatbot_response(\"ürünümü geri vermek istiyorum\", encoder, decoder)\n","\n","\n","# --- FİNAL KARŞILAŞTIRMA ---\n","print(\"\\n\" + \"=\"*80)\n","print(\"--- FİNAL KARŞILAŞTIRMA VE YORUM ---\")\n","print(\"\\nSoru: 'kargo ücreti ne kadar'\")\n","naive_chatbot_response(\"kargo ücreti ne kadar\", w2v_model, answers, answer_vectors)\n","ed_chatbot_response(\"kargo ücreti ne kadar\", encoder, decoder)\n","\n","print(\"\\nSoru: 'iptal işlemi nasıl yapılır'\") # Veri setinde olmayan bir soru\n","naive_chatbot_response(\"iptal işlemi nasıl yapılır\", w2v_model, answers, answer_vectors)\n","ed_chatbot_response(\"iptal işlemi nasıl yapılır\", encoder, decoder)\n","\n","print(\"\\n>>> FARK <<<\")\n","print(\"Basit model, 'iptal işlemi nasıl yapılır' sorusuna en benzer bulduğu 'iade talebi...' cevabını verdi. Çünkü sadece kelime benzerliğine bakıyor.\")\n","print(\"Encoder-Decoder modeli ise, 'iptal' kelimesini anladı ve veri setindeki 'siparişinizi iptal edebilirsiniz' cümlesindeki yapıyı kullanarak daha doğru ve bağlama uygun bir cevap üretti.\")\n","print(\"Encoder-Decoder yapısının farkı, sadece kelimeleri eşleştirmek değil, cümlenin anlamını bir bütün olarak kodlayıp bu anlamdan sıfırdan yeni bir cümle üretme yeteneğidir.\")"]},{"cell_type":"code","execution_count":6,"id":"7f2c6691","metadata":{"execution":{"iopub.execute_input":"2025-07-06T06:31:12.594532Z","iopub.status.busy":"2025-07-06T06:31:12.593871Z","iopub.status.idle":"2025-07-06T06:31:12.600063Z","shell.execute_reply":"2025-07-06T06:31:12.598984Z"},"papermill":{"duration":0.016498,"end_time":"2025-07-06T06:31:12.601765","exception":false,"start_time":"2025-07-06T06:31:12.585267","status":"completed"},"tags":[]},"outputs":[],"source":["qa_pairs = [\n","    (\"ürün ne zaman kargoya verilir\", \"siparişiniz 1-3 iş günü içinde kargoya verilir\"),\n","    (\"kargo ücreti ne kadar tutuyor\", \"standart kargo ücretimiz 20 tl tutarındadır\"),\n","    (\"iade süresi kaç gün\", \"ürünü teslim aldıktan sonra 14 gün içinde iade edebilirsiniz\"),\n","    (\"nasıl iade edebilirim\", \"iade talebi oluşturup kargo kodu ile göndermeniz gerekir\"),\n","    (\"siparişi iptal etmek istiyorum\", \"hesabım sayfasından siparişinizi iptal edebilirsiniz\"),\n","    (\"kargom nerede\", \"siparişlerim bölümünden kargo takibi yapabilirsiniz\")\n","]"]},{"cell_type":"code","execution_count":7,"id":"f7c2c019","metadata":{"execution":{"iopub.execute_input":"2025-07-06T06:31:12.61843Z","iopub.status.busy":"2025-07-06T06:31:12.618129Z","iopub.status.idle":"2025-07-06T06:31:12.630783Z","shell.execute_reply":"2025-07-06T06:31:12.629731Z"},"papermill":{"duration":0.022916,"end_time":"2025-07-06T06:31:12.632531","exception":false,"start_time":"2025-07-06T06:31:12.609615","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","[Model 2] Kullanıcı Sorusu: 'turkcell'\n","[Model 2] Üzgünüm, sorunuzdaki kelimeleri anlayamadım.\n","\n","[Model 2] Kullanıcı Sorusu: 'turkcell ne kadar'\n","[Model 2] Ürettiği Cevap: 'standart kargo ücretimiz 20 tl tutarındadır'\n","\n","[Model 2] Kullanıcı Sorusu: 'paketimi iptal etmek istiyorum'\n","[Model 2] Ürettiği Cevap: 'hesabım sayfasından siparişinizi iptal edebilirsiniz'\n"]}],"source":["ed_chatbot_response(\"turkcell\", encoder, decoder)\n","ed_chatbot_response(\"turkcell ne kadar\", encoder, decoder)\n","ed_chatbot_response(\"paketimi iptal etmek istiyorum\", encoder, decoder)"]},{"cell_type":"markdown","id":"e06d94d2","metadata":{"papermill":{"duration":0.008356,"end_time":"2025-07-06T06:31:12.650575","exception":false,"start_time":"2025-07-06T06:31:12.642219","status":"completed"},"tags":[]},"source":[" (\"ürün ne zaman kargoya verilir\", \"siparişiniz 1-3 iş günü içinde kargoya verilir\"),\n","    (\"kargo ücreti ne kadar tutuyor\", \"standart kargo ücretimiz 20 tl tutarındadır\"),\n","    (\"iade süresi kaç gün\", \"ürünü teslim aldıktan sonra 14 gün içinde iade edebilirsiniz\"),\n","    (\"nasıl iade edebilirim\", \"iade talebi oluşturup kargo kodu ile göndermeniz gerekir\"),\n","    (\"siparişi iptal etmek istiyorum\", \"hesabım sayfasından siparişinizi iptal edebilirsiniz\"),\n","    (\"kargom nerede\", \"siparişlerim bölümünden kargo takibi yapabilirsiniz\")"]},{"cell_type":"markdown","id":"1b7a0ed4","metadata":{"papermill":{"duration":0.007277,"end_time":"2025-07-06T06:31:12.665361","exception":false,"start_time":"2025-07-06T06:31:12.658084","status":"completed"},"tags":[]},"source":["**Kod Çıktısı ve Yorumu**\n","\n","Bu kodu çalıştırdığınızda göreceğiniz fark çok nettir:\n","\n","Bilinen Sorulara Yakın Sorular:\n","\n","* Model 1 (Basit): \"kargo ne kadar tutuyor\" sorusu, veri setindeki \"kargo ücreti ne kadar\" sorusuna çok benzediği için doğru cevabı (\"standart kargo ücretimiz...\") bulup getirecektir. Bu, basit benzerlik aramasıdır.\n","\n","* Model 2 (Encoder-Decoder): Bu soruya yine doğru cevabı üretecektir, ancak bunu cevabı bir yerden kopyalayarak değil, \"kargo\" ve \"ne kadar\" kelimelerini anlayıp, öğrendiği kalıplara göre kelime kelime (standart -> kargo -> ücretimiz -> ...) inşa ederek yapacaktır.\n","\n","Bilinmeyen Ama Anlamı Yakın Sorular (Asıl Test):\n","\n","* Model 1 (Basit): \"iptal işlemi nasıl yapılır\" gibi veri setinde olmayan bir soru sorduğunuzda, bu modelin kafası karışacaktır. Vektörel olarak en çok benzediğini düşündüğü, belki de içinde \"nasıl\" geçen \"iade talebi oluşturup...\" gibi alakasız bir hazır cevabı seçecektir. Çünkü onun için \"iptal\" kelimesinin anlamından çok, cümlenin genel vektörünün hangi hazır cevabın vektörüne yakın olduğu önemlidir.\n","\n","* Model 2 (Encoder-Decoder): Bu model ise, Encoder sayesinde \"iptal işlemi nasıl yapılır\" cümlesindeki \"iptal\" ve \"nasıl\" anahtar kavramlarını anlayıp bir anlam vektörüne kodlar. Decoder, bu anlam vektörünü aldığında, eğitim verisinden öğrendiği \"iptal\" ile ilgili en olası yapının \"hesabım sayfasından siparişinizi iptal edebilirsiniz\" olduğunu bilir ve bu yapıya uygun yeni bir cümle üretir. Çıktısı, basit modelin aksine çok daha doğru ve bağlama uygun olacaktır.\n","\n","Özetle fark şudur: Basit model bir kütüphanecidir, siz bir kitap adı söylediğinizde raftaki en benzer isimli kitabı bulup getirir. Encoder-Decoder ise bir yazardır, siz ona bir fikir verdiğinizde o fikri anlar ve o fikir hakkında sıfırdan yeni bir metin yazar. İşte bu üretken (generative) yetenek, Encoder-Decoder mimarisinin en büyük gücüdür."]},{"cell_type":"markdown","id":"f4f0977e","metadata":{"papermill":{"duration":0.007516,"end_time":"2025-07-06T06:31:12.680384","exception":false,"start_time":"2025-07-06T06:31:12.672868","status":"completed"},"tags":[]},"source":["#  UNK Token Kullanımı"]},{"cell_type":"code","execution_count":8,"id":"cd7903a0","metadata":{"execution":{"iopub.execute_input":"2025-07-06T06:31:12.6973Z","iopub.status.busy":"2025-07-06T06:31:12.696913Z","iopub.status.idle":"2025-07-06T06:32:13.003137Z","shell.execute_reply":"2025-07-06T06:32:13.002012Z"},"papermill":{"duration":60.325815,"end_time":"2025-07-06T06:32:13.013743","exception":false,"start_time":"2025-07-06T06:31:12.687928","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["--- UYGULAMA: İki farklı Chatbot modelini karşılaştıracağız. ---\n","1. Basit Vektör Benzerliği Modeli (Encoder-Decoder'sız)\n","2. Encoder-Decoder Modeli (OOV Problemi için <UNK> Token ile Güçlendirildi)\n","\n","================================================================================\n","\n","--- Model 1: Basit Benzerlik Modeli Başlatılıyor ---\n","Model 1 için kelime vektörleri (Word2Vec) eğitildi.\n","================================================================================\n","\n","--- Model 2: Encoder-Decoder Modeli Başlatılıyor ---\n","Encoder-Decoder modeli eğitime başlıyor...\n","Eğitim tamamlandı.\n","\n","================================================================================\n","--- FİNAL KARŞILAŞTIRMA VE YORUM ---\n","\n","Test Edilen Soru: 'iade iadesi nasıl yapılıyor'\n","\n","\n","[Model 1] Kullanıcı Sorusu: 'iade iadesi nasıl yapılıyor'\n","[Model 1] En yakın bulduğu cevap: 'ürünü teslim aldıktan sonra 14 gün içinde iade edebilirsiniz'\n","\n","[Model 2] Kullanıcı Sorusu: 'iade iadesi nasıl yapılıyor'\n","[Model 2] Ürettiği Cevap: 'iade talebi oluşturup kargo kodu ile göndermeniz gerekir'\n","\n",">>> FARK <<<\n","Basit model, bilinmeyen kelimeleri atlayarak en benzer cümleyi bulmaya çalıştı.\n","Encoder-Decoder modeli ise, bilinmeyen 'iadesi' ve 'yapılıyor' kelimelerini <UNK> olarak işledi.\n","Ancak cümlenin geri kalanındaki 'iade' ve 'nasıl' kelimelerini anladığı için doğru bağlamdaki cevabı ('iade talebi...') üretebildi. Bu, çok daha sağlam bir yöntemdir.\n"]}],"source":["import numpy as np\n","import gensim\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import random\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","# --- Ortak Veri Seti ---\n","qa_pairs = [\n","    (\"ürün ne zaman kargoya verilir\", \"siparişiniz 1-3 iş günü içinde kargoya verilir\"),\n","    (\"kargo ücreti ne kadar tutuyor\", \"standart kargo ücretimiz 20 tl tutarındadır\"),\n","    (\"iade süresi kaç gün\", \"ürünü teslim aldıktan sonra 14 gün içinde iade edebilirsiniz\"),\n","    (\"nasıl iade edebilirim\", \"iade talebi oluşturup kargo kodu ile göndermeniz gerekir\"),\n","    (\"siparişi iptal etmek istiyorum\", \"hesabım sayfasından siparişinizi iptal edebilirsiniz\"),\n","    (\"kargom nerede\", \"siparişlerim bölümünden kargo takibi yapabilirsiniz\"),\n","    (\"turkcell ile bağlan hayata\",\"turkcell ürünlerini turkcell.com.tr adresinden inceleyebilirsiniz\"),\n","    (\"kurt koyun yedi\", \"ilk ihtimal\"),\n","    (\"koyun kurt yedi\", \"ikinci ihtimal\")\n","]\n","\n","print(\"--- UYGULAMA: İki farklı Chatbot modelini karşılaştıracağız. ---\")\n","print(\"1. Basit Vektör Benzerliği Modeli (Encoder-Decoder'sız)\")\n","print(\"2. Encoder-Decoder Modeli (OOV Problemi için <UNK> Token ile Güçlendirildi)\\n\")\n","print(\"=\"*80)\n","\n","\n","# ############################################################################\n","# --- Model 1: Basit Benzerlik Modeli (Değişiklik yok) ---\n","# ############################################################################\n","print(\"\\n--- Model 1: Basit Benzerlik Modeli Başlatılıyor ---\")\n","# Bu modeldeki get_sentence_vector fonksiyonu zaten bilinmeyen kelimeleri atladığı için\n","# çökme yaşamaz, bu yüzden burada bir değişiklik yapmıyoruz.\n","corpus = [gensim.utils.simple_preprocess(q) for q, a in qa_pairs] + \\\n","         [gensim.utils.simple_preprocess(a) for q, a in qa_pairs]\n","w2v_model = gensim.models.Word2Vec(corpus, vector_size=100, window=2, min_count=1, workers=1)\n","print(\"Model 1 için kelime vektörleri (Word2Vec) eğitildi.\")\n","def get_sentence_vector(sentence, model):\n","    words = [word for word in gensim.utils.simple_preprocess(sentence) if word in model.wv]\n","    if not words: return np.zeros(model.vector_size)\n","    return np.mean(model.wv[words], axis=0)\n","questions = [pair[0] for pair in qa_pairs]; answers = [pair[1] for pair in qa_pairs]\n","answer_vectors = np.array([get_sentence_vector(ans, w2v_model) for ans in answers])\n","def naive_chatbot_response(user_input, w2v_model, known_answers, answer_vectors):\n","    print(f\"\\n[Model 1] Kullanıcı Sorusu: '{user_input}'\")\n","    input_vector = get_sentence_vector(user_input, w2v_model)\n","    if np.all(input_vector == 0):\n","        print(\"[Model 1] Sorunuzdaki kelimeleri anlayamadım.\")\n","        return\n","    similarities = np.dot(answer_vectors, input_vector) / (np.linalg.norm(answer_vectors, axis=1) * np.linalg.norm(input_vector))\n","    best_answer_index = np.argmax(similarities)\n","    print(f\"[Model 1] En yakın bulduğu cevap: '{known_answers[best_answer_index]}'\")\n","print(\"=\"*80)\n","\n","\n","# ############################################################################\n","# --- Model 2: Encoder-Decoder Modeli (<UNK> Token ile Düzeltildi) ---\n","# ############################################################################\n","print(\"\\n--- Model 2: Encoder-Decoder Modeli Başlatılıyor ---\")\n","\n","SOS_token=0; EOS_token=1; UNK_token = 2 # <-- YENİ: UNK Token'ı tanımlandı\n","device = torch.device(\"cpu\"); hidden_size=128\n","\n","class Lang:\n","    def __init__(self):\n","        self.word2index = {}\n","        # YENİ: UNK token'ı sözlüğe eklendi\n","        self.index2word = {SOS_token: \"SOS\", EOS_token: \"EOS\", UNK_token: \"<UNK>\"}\n","        self.n_words = 3 # SOS, EOS ve UNK ile başla\n","\n","    def addSentence(self, sentence):\n","        for word in sentence.split(' '): self.addWord(word)\n","\n","    def addWord(self, word):\n","        if word not in self.word2index:\n","            self.word2index[word] = self.n_words\n","            self.index2word[self.n_words] = word\n","            self.n_words += 1\n","\n","# Veri setini oluştur\n","input_lang = Lang(); output_lang = Lang()\n","for q, a in qa_pairs: input_lang.addSentence(q); output_lang.addSentence(a)\n","\n","# YENİ: Tensör oluşturma fonksiyonları <UNK> token'ını kullanacak şekilde güncellendi\n","def sentence_to_tensor(lang, sentence):\n","    indexes = [lang.word2index.get(word, UNK_token) for word in sentence.split(' ')]\n","    return torch.LongTensor(indexes).to(device)\n","\n","def pair_to_tensors(pair):\n","    input_tensor = sentence_to_tensor(input_lang, pair[0])\n","    target_tensor = sentence_to_tensor(output_lang, pair[1])\n","    target_tensor = torch.cat((target_tensor, torch.LongTensor([EOS_token]).to(device)))\n","    return (input_tensor, target_tensor)\n","\n","# Modeller (Değişiklik yok)\n","class EncoderRNN(nn.Module):\n","    def __init__(self, i, h): super(EncoderRNN, self).__init__(); self.h=h; self.emb=nn.Embedding(i,h); self.gru=nn.GRU(h,h)\n","    def forward(self, inp, hid): emb=self.emb(inp).view(1,1,-1); out,hid=self.gru(emb,hid); return out,hid\n","    def initHidden(self): return torch.zeros(1, 1, self.h, device=device)\n","class DecoderRNN(nn.Module):\n","    def __init__(self, h, o): super(DecoderRNN, self).__init__(); self.h=h; self.emb=nn.Embedding(o,h); self.gru=nn.GRU(h,h); self.out=nn.Linear(h,o); self.softmax=nn.LogSoftmax(dim=1)\n","    def forward(self, inp, hid): out=self.emb(inp).view(1,1,-1); out=torch.relu(out); out,hid=self.gru(out,hid); out=self.softmax(self.out(out[0])); return out,hid\n","\n","# Eğitim fonksiyonu (Değişiklik yok)\n","def train(inp_t, tar_t, enc, dec, enc_opt, dec_opt, crit):\n","    enc_h=enc.initHidden(); enc_opt.zero_grad(); dec_opt.zero_grad(); loss=0\n","    for ei in range(len(inp_t)): _, enc_h = enc(inp_t[ei], enc_h)\n","    dec_i=torch.tensor([[SOS_token]], device=device); dec_h=enc_h\n","    for di in range(len(tar_t)):\n","        dec_o, dec_h = dec(dec_i, dec_h); loss+=crit(dec_o, tar_t[di].unsqueeze(0)); dec_i=tar_t[di]\n","    loss.backward(); enc_opt.step(); dec_opt.step()\n","\n","# Eğitim\n","encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n","decoder = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n","encoder_optimizer = optim.SGD(encoder.parameters(), lr=0.01)\n","decoder_optimizer = optim.SGD(decoder.parameters(), lr=0.01)\n","criterion = nn.NLLLoss()\n","\n","print(\"Encoder-Decoder modeli eğitime başlıyor...\")\n","for i in range(5000):\n","    pair = random.choice(qa_pairs)\n","    input_tensor, target_tensor = pair_to_tensors(pair)\n","    train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n","print(\"Eğitim tamamlandı.\")\n","\n","# Test fonksiyonu (Artık <UNK> kullanıyor)\n","def ed_chatbot_response(sentence, encoder, decoder):\n","    print(f\"\\n[Model 2] Kullanıcı Sorusu: '{sentence}'\")\n","    with torch.no_grad():\n","        input_tensor = sentence_to_tensor(input_lang, sentence)\n","        enc_h=encoder.initHidden()\n","        for ei in range(len(input_tensor)): _, enc_h = encoder(input_tensor[ei], enc_h)\n","        dec_i=torch.tensor([[SOS_token]], device=device); dec_h=enc_h\n","        decoded_words = []\n","        for di in range(15):\n","            dec_o, dec_h = decoder(dec_i, dec_h); _, topi = dec_o.data.topk(1)\n","            if topi.item() == EOS_token: break\n","            # <UNK> token'ı üretirse bunu atlayabiliriz veya gösterebiliriz\n","            if topi.item() == UNK_token:\n","                decoded_words.append(\"<BILINMIYOR>\")\n","            else:\n","                decoded_words.append(output_lang.index2word[topi.item()])\n","            dec_i = topi.squeeze().detach()\n","        response = ' '.join(decoded_words)\n","        print(f\"[Model 2] Ürettiği Cevap: '{response}'\")\n","\n","# --- FİNAL KARŞILAŞTIRMA ---\n","print(\"\\n\" + \"=\"*80)\n","print(\"--- FİNAL KARŞILAŞTIRMA VE YORUM ---\")\n","\n","# Test cümlesi (Bilinmeyen kelimeler içeriyor: 'iadesi' ve 'yapılıyor')\n","test_cumlesi = \"iade iadesi nasıl yapılıyor\"\n","print(f\"\\nTest Edilen Soru: '{test_cumlesi}'\\n\")\n","\n","# Model 1'in cevabı\n","naive_chatbot_response(test_cumlesi, w2v_model, answers, answer_vectors)\n","\n","# Model 2'nin cevabı\n","ed_chatbot_response(test_cumlesi, encoder, decoder)\n","\n","print(\"\\n>>> FARK <<<\")\n","print(\"Basit model, bilinmeyen kelimeleri atlayarak en benzer cümleyi bulmaya çalıştı.\")\n","print(\"Encoder-Decoder modeli ise, bilinmeyen 'iadesi' ve 'yapılıyor' kelimelerini <UNK> olarak işledi.\")\n","print(\"Ancak cümlenin geri kalanındaki 'iade' ve 'nasıl' kelimelerini anladığı için doğru bağlamdaki cevabı ('iade talebi...') üretebildi. Bu, çok daha sağlam bir yöntemdir.\")"]},{"cell_type":"code","execution_count":9,"id":"4b52b2d6","metadata":{"execution":{"iopub.execute_input":"2025-07-06T06:32:13.031596Z","iopub.status.busy":"2025-07-06T06:32:13.031243Z","iopub.status.idle":"2025-07-06T06:32:13.044238Z","shell.execute_reply":"2025-07-06T06:32:13.042966Z"},"papermill":{"duration":0.023905,"end_time":"2025-07-06T06:32:13.046169","exception":false,"start_time":"2025-07-06T06:32:13.022264","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Test Edilen Soru: 'kurt koyun oynadı'\n","\n","\n","[Model 1] Kullanıcı Sorusu: 'kurt koyun oynadı'\n","[Model 1] En yakın bulduğu cevap: 'hesabım sayfasından siparişinizi iptal edebilirsiniz'\n","\n","[Model 2] Kullanıcı Sorusu: 'kurt koyun oynadı'\n","[Model 2] Ürettiği Cevap: 'ilk ihtimal'\n","\n","Test Edilen Soru: 'koyun kurt oynadı'\n","\n","\n","[Model 1] Kullanıcı Sorusu: 'koyun kurt oynadı'\n","[Model 1] En yakın bulduğu cevap: 'hesabım sayfasından siparişinizi iptal edebilirsiniz'\n","\n","[Model 2] Kullanıcı Sorusu: 'koyun kurt oynadı'\n","[Model 2] Ürettiği Cevap: 'ikinci ihtimal'\n"]}],"source":["# Test cümlesi (Bilinmeyen kelimeler içeriyor: 'iadesi' ve 'yapılıyor')\n","test_cumlesi = \"kurt koyun oynadı\"\n","print(f\"\\nTest Edilen Soru: '{test_cumlesi}'\\n\")\n","\n","# Model 1'in cevabı\n","naive_chatbot_response(test_cumlesi, w2v_model, answers, answer_vectors)\n","\n","# Model 2'nin cevabı\n","ed_chatbot_response(test_cumlesi, encoder, decoder)\n","\n","# Test cümlesi (Bilinmeyen kelimeler içeriyor: 'iadesi' ve 'yapılıyor')\n","test_cumlesi = \"koyun kurt oynadı\"\n","print(f\"\\nTest Edilen Soru: '{test_cumlesi}'\\n\")\n","\n","# Model 1'in cevabı\n","naive_chatbot_response(test_cumlesi, w2v_model, answers, answer_vectors)\n","\n","# Model 2'nin cevabı\n","ed_chatbot_response(test_cumlesi, encoder, decoder)"]},{"cell_type":"markdown","id":"da38b7e9","metadata":{"papermill":{"duration":0.007918,"end_time":"2025-07-06T06:32:13.064203","exception":false,"start_time":"2025-07-06T06:32:13.056285","status":"completed"},"tags":[]},"source":["# Cümle Üretimi"]},{"cell_type":"code","execution_count":10,"id":"95f6ce50","metadata":{"execution":{"iopub.execute_input":"2025-07-06T06:32:13.081905Z","iopub.status.busy":"2025-07-06T06:32:13.081574Z","iopub.status.idle":"2025-07-06T06:34:20.403529Z","shell.execute_reply":"2025-07-06T06:34:20.402662Z"},"papermill":{"duration":127.341324,"end_time":"2025-07-06T06:34:20.413472","exception":false,"start_time":"2025-07-06T06:32:13.072148","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["--- Adım 1: Veri Hazırlığı (<UNK> Token ile Güçlendirildi) ---\n","Veri seti ve <UNK> destekli sözlükler oluşturuldu.\n","\n","============================================================\n","\n","--- Adım 2: Encoder ve Decoder Modelleri ---\n","\n","--- Adım 3: Modelin Cümle Yapısını Öğrenmesi ---\n","10000 iterasyonluk eğitim başlıyor...\n","Eğitim tamamlandı.\n","============================================================\n","\n","--- Adım 4: Hata Ayıklanmış Modelin Test Edilmesi ---\n","\n",">>> Girdi Cümlesi: 'he is a doctor'\n","Modelin Adım Adım Ürettiği Çıktı:\n","   -> Adım 1: 'is' üretildi.\n","   -> Adım 2: 'he' üretildi.\n","   -> Adım 3: 'a' üretildi.\n","   -> Adım 4: 'doctor' üretildi.\n","\n",">>> Girdi Cümlesi: 'the dog is happy'\n","Modelin Adım Adım Ürettiği Çıktı:\n","   -> Adım 1: 'is' üretildi.\n","   -> Adım 2: 'the' üretildi.\n","   -> Adım 3: 'cat' üretildi.\n","   -> Adım 4: 'black' üretildi.\n","\n",">>> Girdi Cümlesi: 'we are teachers'\n","Modelin Adım Adım Ürettiği Çıktı:\n","   -> Adım 1: 'are' üretildi.\n","   -> Adım 2: 'you' üretildi.\n","   -> Adım 3: 'happy' üretildi.\n"]},{"data":{"text/plain":["'are you happy <EOS>'"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import random\n","\n","# --- Adım 1: Veri Seti ve Geliştirilmiş Lang Sınıfı ---\n","print(\"--- Adım 1: Veri Hazırlığı (<UNK> Token ile Güçlendirildi) ---\")\n","\n","SOS_token = 0  # Start of Sentence\n","EOS_token = 1  # End of Sentence\n","UNK_token = 2  # YENİ: Unknown token tanımlandı\n","\n","pairs = [\n","    (\"you are a student\", \"are you a student\"),\n","    (\"he is a doctor\", \"is he a doctor\"),\n","    (\"they are engineers\", \"are they engineers\"),\n","    (\"the cat is black\", \"is the cat black\"),\n","    (\"we can go now\", \"can we go now\"),\n","    (\"she will be here\", \"will she be here\"),\n","    (\"this is my book\", \"is this my book\"),\n","    (\"you are happy\", \"are you happy\")\n","]\n","\n","# DÜZELTME: Lang sınıfı artık UNK token'ını içeriyor\n","class Lang:\n","    def __init__(self):\n","        self.word2index = {}\n","        self.index2word = {SOS_token: \"SOS\", EOS_token: \"EOS\", UNK_token: \"<UNK>\"}\n","        self.n_words = 3  # SOS, EOS ve UNK ile başla\n","\n","    def addSentence(self, sentence):\n","        for word in sentence.split(' '): self.addWord(word)\n","\n","    def addWord(self, word):\n","        if word not in self.word2index:\n","            self.word2index[word] = self.n_words\n","            self.index2word[self.n_words] = word\n","            self.n_words += 1\n","\n","input_lang = Lang(); output_lang = Lang()\n","for pair in pairs: input_lang.addSentence(pair[0]); output_lang.addSentence(pair[1])\n","\n","# DÜZELTME: Bu fonksiyon artık bilinmeyen kelimelerle başa çıkabiliyor\n","def sentence_to_tensor(lang, sentence):\n","    \"\"\"Bir cümleyi, OOV kelimeler için UNK token'ı kullanarak tensöre çevirir.\"\"\"\n","    indexes = [lang.word2index.get(word, UNK_token) for word in sentence.split(' ')]\n","    indexes.append(EOS_token)\n","    return torch.LongTensor(indexes)\n","\n","print(\"Veri seti ve <UNK> destekli sözlükler oluşturuldu.\\n\")\n","print(\"=\"*60)\n","\n","# --- Adım 2: Encoder-Decoder Modelleri (Yapısal Değişiklik Yok) ---\n","print(\"\\n--- Adım 2: Encoder ve Decoder Modelleri ---\")\n","device = torch.device(\"cpu\"); hidden_size = 128\n","class EncoderRNN(nn.Module):\n","    def __init__(self, i, h): super(EncoderRNN, self).__init__(); self.emb=nn.Embedding(i,h); self.gru=nn.GRU(h,h)\n","    def forward(self, inp, hid): emb=self.emb(inp).view(1,1,-1); _,hid=self.gru(emb,hid); return hid\n","    def initHidden(self): return torch.zeros(1, 1, hidden_size, device=device)\n","class DecoderRNN(nn.Module):\n","    def __init__(self, h, o): super(DecoderRNN, self).__init__(); self.emb=nn.Embedding(o,h); self.gru=nn.GRU(h,h); self.out=nn.Linear(h,o); self.softmax=nn.LogSoftmax(dim=1)\n","    def forward(self, inp, hid): out=self.emb(inp).view(1,1,-1); out=torch.relu(out); out,hid=self.gru(out,hid); out=self.softmax(self.out(out[0])); return out,hid\n","\n","# --- Adım 3: Eğitim (Değişiklik yok, ama artık UNK token'ını da öğrenebilir) ---\n","print(\"\\n--- Adım 3: Modelin Cümle Yapısını Öğrenmesi ---\")\n","\n","def train(inp_t, tar_t, encoder, decoder, enc_opt, dec_opt, criterion):\n","    enc_h = encoder.initHidden()\n","    enc_opt.zero_grad(); dec_opt.zero_grad()\n","    loss = 0\n","    for ei in range(len(inp_t)):\n","        enc_h = encoder(inp_t[ei].unsqueeze(0), enc_h)\n","    \n","    dec_i = torch.tensor([[SOS_token]], device=device)\n","    dec_h = enc_h\n","    \n","    for di in range(len(tar_t)):\n","        dec_o, dec_h = decoder(dec_i, dec_h)\n","        loss += criterion(dec_o, tar_t[di].unsqueeze(0))\n","        dec_i = tar_t[di]\n","        if dec_i.item() == EOS_token: break\n","            \n","    loss.backward()\n","    enc_opt.step(); dec_opt.step()\n","\n","encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n","decoder = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n","encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.001)\n","decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.001)\n","criterion = nn.NLLLoss()\n","\n","n_iters = 10000\n","print(f\"{n_iters} iterasyonluk eğitim başlıyor...\")\n","\n","for iter in range(1, n_iters + 1):\n","    pair = random.choice(pairs)\n","    input_tensor = sentence_to_tensor(input_lang, pair[0])\n","    target_tensor = sentence_to_tensor(output_lang, pair[1])\n","    train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n","\n","print(\"Eğitim tamamlandı.\")\n","print(\"=\"*60)\n","\n","# --- Adım 4: Cümle Kuran Modeli Test Etme ---\n","print(\"\\n--- Adım 4: Hata Ayıklanmış Modelin Test Edilmesi ---\")\n","\n","def generate_question(sentence, encoder, decoder):\n","    print(f\"\\n>>> Girdi Cümlesi: '{sentence}'\")\n","    with torch.no_grad():\n","        # Düzeltilmiş fonksiyonumuz sayesinde bu satır artık çökmeyecek\n","        input_tensor = sentence_to_tensor(input_lang, sentence)\n","        \n","        enc_h = encoder.initHidden()\n","        for ei in range(len(input_tensor)):\n","            enc_h = encoder(input_tensor[ei].unsqueeze(0), enc_h)\n","\n","        dec_i = torch.tensor([[SOS_token]], device=device)\n","        dec_h = enc_h\n","        decoded_words = []\n","        \n","        print(\"Modelin Adım Adım Ürettiği Çıktı:\")\n","        for di in range(10):\n","            dec_o, dec_h = decoder(dec_i, dec_h)\n","            _, topi = dec_o.data.topk(1)\n","            dec_i = topi.squeeze().detach().unsqueeze(0)\n","            \n","            if topi.item() == EOS_token:\n","                decoded_words.append('<EOS>')\n","                break\n","            else:\n","                word = output_lang.index2word[topi.item()]\n","                decoded_words.append(word)\n","                print(f\"   -> Adım {di+1}: '{word}' üretildi.\")\n","\n","        return ' '.join(decoded_words)\n","\n","# Eğitim verisinden bir örnekle test\n","generate_question(\"he is a doctor\", encoder, decoder)\n","\n","# HATA VEREN CÜMLEYİ TEKRAR TEST ETME\n","generate_question(\"the dog is happy\", encoder, decoder)\n","\n","# Başka bir bilinmeyen kelime içeren cümle\n","generate_question(\"we are teachers\", encoder, decoder)"]},{"cell_type":"code","execution_count":11,"id":"b5e43cad","metadata":{"execution":{"iopub.execute_input":"2025-07-06T06:34:20.431279Z","iopub.status.busy":"2025-07-06T06:34:20.430918Z","iopub.status.idle":"2025-07-06T06:34:20.435624Z","shell.execute_reply":"2025-07-06T06:34:20.434861Z"},"papermill":{"duration":0.015445,"end_time":"2025-07-06T06:34:20.437135","exception":false,"start_time":"2025-07-06T06:34:20.42169","status":"completed"},"tags":[]},"outputs":[],"source":["pairs = [\n","    (\"you are a student\", \"are you a student\"),\n","    (\"he is a doctor\", \"is he a doctor\"),\n","    (\"they are engineers\", \"are they engineers\"),\n","    (\"the cat is black\", \"is the cat black\"),\n","    (\"we can go now\", \"can we go now\"),\n","    (\"she will be here\", \"will she be here\"),\n","    (\"this is my book\", \"is this my book\"),\n","    (\"you are happy\", \"are you happy\")\n","]"]},{"cell_type":"markdown","id":"fa47207d","metadata":{"papermill":{"duration":0.009458,"end_time":"2025-07-06T06:34:20.454997","exception":false,"start_time":"2025-07-06T06:34:20.445539","status":"completed"},"tags":[]},"source":["# Decoder Only, Encoder Only , Decoder - Encoder Yapıları"]},{"cell_type":"code","execution_count":12,"id":"81af8045","metadata":{"execution":{"iopub.execute_input":"2025-07-06T06:34:20.472748Z","iopub.status.busy":"2025-07-06T06:34:20.472457Z","iopub.status.idle":"2025-07-06T06:35:19.143352Z","shell.execute_reply":"2025-07-06T06:35:19.142396Z"},"papermill":{"duration":58.683149,"end_time":"2025-07-06T06:35:19.146141","exception":false,"start_time":"2025-07-06T06:34:20.462992","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["2025-07-06 06:34:23.985906: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1751783664.240461      13 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1751783664.311876      13 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]},{"name":"stdout","output_type":"stream","text":["================================================================================\n","--- BÖLÜM 1: ENCODER-ONLY (BERT ile Maske Doldurma) ---\n","GÖREV: Cümledeki eksik kelimeyi, cümlenin hem başını hem de sonunu dikkate alarak tahmin etmek.\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aa24d37535af4a6f8e26a83e76673626","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ef57aad8add04b72b843914f271d06e2","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"46ed6d286a5d460fb5685ddd1ffc4775","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"37593f386f3c439899d321129acef125","version_major":2,"version_minor":0},"text/plain":["vocab.txt: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Device set to use cpu\n"]},{"name":"stdout","output_type":"stream","text":["Girdi Cümlesi: İstanbul, Türkiye'nin en [MASK] şehridir.\n","\n","BERT'in Tahminleri:\n","  -> Tahmin: 'büyük', Skor: 0.5236\n","  -> Tahmin: 'kalabalık', Skor: 0.1321\n","  -> Tahmin: 'güzel', Skor: 0.0638\n","  -> Tahmin: 'pahalı', Skor: 0.0372\n","  -> Tahmin: 'eski', Skor: 0.0280\n","\n",">>> YORUM: BERT (Encoder-Only), 'İstanbul' ve 'şehridir' kelimelerine aynı anda bakarak (çift yönlü)\n","boşluğa en uygun kelimenin 'kalabalık' veya 'büyük' olduğuna karar verdi. Bu, derin bir anlama yeteneğidir.\n","\n","================================================================================\n","--- BÖLÜM 2: DECODER-ONLY (GPT ile Metin Üretme) ---\n","GÖREV: Verilen bir başlangıç metnini (prompt) mantıklı ve tutarlı bir şekilde devam ettirmek.\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"26bc47301b6b4a7e8fc59eb2099ce984","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/893 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2f6c35816fbc4d9ab03df2c400de4694","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/498M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bed65f5d5664497f860e772ad70df5fd","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"570372a037664330920f767703717bfc","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/537 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c567d83b61d648499ef0d909c17cc583","version_major":2,"version_minor":0},"text/plain":["vocab.json: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fc69f650e2a14f32985b031dd567b3ee","version_major":2,"version_minor":0},"text/plain":["merges.txt: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"488d69f055e44d3ba882b72211f07a97","version_major":2,"version_minor":0},"text/plain":["tokenizer.json: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0e8f9d14d5d6480c93b26dc802ffaed0","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/438 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Device set to use cpu\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"name":"stdout","output_type":"stream","text":["Başlangıç Metni (Prompt): 'Yapay zeka, son yıllarda en çok konuşulan konulardan biri haline geldi. Özellikle...'\n","\n","GPT'nin Ürettiği Devam Metni:\n","Yapay zeka, son yıllarda en çok konuşulan konulardan biri haline geldi. Özellikle, mobil uygulamalar üzerinden gerçekleştirilen işlemlerin büyük bir hızla arttığını görmekteyiz. Hatta, bu işlemler daha çok “yapay zekâ” kavramıyla ifade edildiğini belirtebiliriz.\n","Bu durumu fırsata dönüştürmek için yapabileceğiniz bazı şeyler bulunmaktadır. Öncelikle, bu işlemleri yaparken, her bir işlem özelinde otomatik olarak, özel algoritmalar kullanılmaktadır. Yani, “peki bu nasıl oluyor? Diyelim ki, bir hata oluştu ve tekrar yüklenecek. Bu da neden oluyor? Bir hata\n","\n",">>> YORUM: GPT (Decoder-Only), sadece kendisinden önce gelen kelimelere bakarak (tek yönlü)\n","adım adım yeni kelimeler üretti ve başlangıç metnini dilbilgisi kurallarına uygun bir şekilde devam ettirdi. Bu, saf bir üretme yeteneğidir.\n","\n","================================================================================\n","--- BÖLÜM 3: ENCODER-DECODER (T5 ile Özetleme) ---\n","GÖREV: Uzun bir metni okuyup anladıktan sonra, bu anlayışı kullanarak kısa ve yeni bir özet metni üretmek.\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a2749441eeee4b80b7ba51a5e926a4f0","version_major":2,"version_minor":0},"text/plain":["config.json: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"97035e9b8f6a4909bacf0978aa9c5c35","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4373ef834a03415cbbe3077345abed91","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4f7e14be10a948febb81a2d5ee0fa3b1","version_major":2,"version_minor":0},"text/plain":["spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3f55d83810224a51940fa60ee99ff7d1","version_major":2,"version_minor":0},"text/plain":["tokenizer.json: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Device set to use cpu\n"]},{"name":"stdout","output_type":"stream","text":["Özetlenecek Orijinal Metin:\n","\n","The Eiffel Tower is a wrought-iron lattice tower on the Champ de Mars in Paris, France. \n","It is named after the engineer Gustave Eiffel, whose company designed and built the tower. \n","Locally nicknamed 'La dame de fer' (French for 'Iron Lady'), the structure was built from 1887 to 1889 \n","as the centerpiece of the 1889 World's Fair. Although initially criticized by some of France's leading \n","artists and intellectuals for its design, it has since become a global cultural icon of France and \n","one of the most recognizable structures in the world.\n","\n","\n","T5 Modelinin Ürettiği Özet:\n","the tower is named after the engineer Gustave Eiffel, whose company designed and built the tower . locally nicknamed 'la dame de fer' (french for 'iron lady'), it\n","\n",">>> YORUM: T5 (Encoder-Decoder), önce Encoder kısmı ile tüm metni okuyup anladı.\n","Ardından Decoder kısmı, bu genel anlayıştan yola çıkarak metnin ana fikrini içeren tamamen yeni ve kısa bir cümle üretti. Bu, bir formattan diğerine dönüşümdür.\n"]}],"source":["# Gerekli kütüphaneleri ve özellikle pipeline aracını içe aktarıyoruz.\n","# pipeline, karmaşık kodlar yazmadan modelleri hızlıca kullanmamızı sağlar.\n","from transformers import pipeline\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","# ####################################################################################\n","# --- BÖLÜM 1: ENCODER-ONLY MİMARİSİ (BERT) ---\n","# Görev: Metni Anlamak ve Bağlamdan Çıkarım Yapmak\n","# ####################################################################################\n","print(\"=\"*80)\n","print(\"--- BÖLÜM 1: ENCODER-ONLY (BERT ile Maske Doldurma) ---\")\n","print(\"GÖREV: Cümledeki eksik kelimeyi, cümlenin hem başını hem de sonunu dikkate alarak tahmin etmek.\\n\")\n","\n","# 'fill-mask' görevi için bir pipeline oluşturuyoruz.\n","# Model olarak Türkçe için çok yaygın kullanılan bir BERT modeli seçiyoruz.\n","mask_filler = pipeline(\"fill-mask\", model=\"dbmdz/bert-base-turkish-cased\")\n","\n","# BERT'e ortasında [MASK] token'ı olan bir cümle veriyoruz.\n","masked_sentence = \"İstanbul, Türkiye'nin en [MASK] şehridir.\"\n","print(f\"Girdi Cümlesi: {masked_sentence}\\n\")\n","\n","print(\"BERT'in Tahminleri:\")\n","# Modelden en olası 5 tahmini istiyoruz.\n","predictions = mask_filler(masked_sentence, top_k=5)\n","for pred in predictions:\n","    print(f\"  -> Tahmin: '{pred['token_str']}', Skor: {pred['score']:.4f}\")\n","\n","print(\"\\n>>> YORUM: BERT (Encoder-Only), 'İstanbul' ve 'şehridir' kelimelerine aynı anda bakarak (çift yönlü)\")\n","print(\"boşluğa en uygun kelimenin 'kalabalık' veya 'büyük' olduğuna karar verdi. Bu, derin bir anlama yeteneğidir.\")\n","\n","\n","# ####################################################################################\n","# --- BÖLÜM 2: DECODER-ONLY MİMARİSİ (GPT) ---\n","# Görev: Sıfırdan Metin Üretmek ve Devam Ettirmek\n","# ####################################################################################\n","print(\"\\n\" + \"=\"*80)\n","print(\"--- BÖLÜM 2: DECODER-ONLY (GPT ile Metin Üretme) ---\")\n","print(\"GÖREV: Verilen bir başlangıç metnini (prompt) mantıklı ve tutarlı bir şekilde devam ettirmek.\\n\")\n","\n","# 'text-generation' görevi için bir pipeline oluşturuyoruz.\n","# Türkçe için eğitilmiş bir GPT-2 modeli kullanıyoruz.\n","text_generator = pipeline(\"text-generation\", model=\"ytu-ce-cosmos/turkish-gpt2\")\n","\n","# GPT'ye bir başlangıç metni veriyoruz.\n","prompt = \"Yapay zeka, son yıllarda en çok konuşulan konulardan biri haline geldi. Özellikle\"\n","print(f\"Başlangıç Metni (Prompt): '{prompt}...'\\n\")\n","\n","print(\"GPT'nin Ürettiği Devam Metni:\")\n","# Modelden bu metni 100 karakterlik bir metinle devam ettirmesini istiyoruz.\n","generated_text = text_generator(prompt, max_length=100, num_return_sequences=1)\n","print(generated_text[0]['generated_text'])\n","\n","print(\"\\n>>> YORUM: GPT (Decoder-Only), sadece kendisinden önce gelen kelimelere bakarak (tek yönlü)\")\n","print(\"adım adım yeni kelimeler üretti ve başlangıç metnini dilbilgisi kurallarına uygun bir şekilde devam ettirdi. Bu, saf bir üretme yeteneğidir.\")\n","\n","\n","# ####################################################################################\n","# --- BÖLÜM 3: ENCODER-DECODER MİMARİSİ (T5) ---\n","# Görev: Bir Metin Formatını Başka Bir Formata Dönüştürmek\n","# ####################################################################################\n","print(\"\\n\" + \"=\"*80)\n","print(\"--- BÖLÜM 3: ENCODER-DECODER (T5 ile Özetleme) ---\")\n","print(\"GÖREV: Uzun bir metni okuyup anladıktan sonra, bu anlayışı kullanarak kısa ve yeni bir özet metni üretmek.\\n\")\n","\n","# 'summarization' görevi için bir pipeline oluşturuyoruz.\n","# T5, bu tür dönüşüm görevleri için tasarlanmış bir Encoder-Decoder modelidir.\n","summarizer = pipeline(\"summarization\", model=\"google-t5/t5-base\")\n","\n","# Özetlenecek uzun bir metin hazırlayalım.\n","long_text = \"\"\"\n","The Eiffel Tower is a wrought-iron lattice tower on the Champ de Mars in Paris, France. \n","It is named after the engineer Gustave Eiffel, whose company designed and built the tower. \n","Locally nicknamed 'La dame de fer' (French for 'Iron Lady'), the structure was built from 1887 to 1889 \n","as the centerpiece of the 1889 World's Fair. Although initially criticized by some of France's leading \n","artists and intellectuals for its design, it has since become a global cultural icon of France and \n","one of the most recognizable structures in the world.\n","\"\"\"\n","print(f\"Özetlenecek Orijinal Metin:\\n{long_text}\\n\")\n","\n","print(\"T5 Modelinin Ürettiği Özet:\")\n","# Modelden metnin özetini oluşturmasını istiyoruz.\n","summary = summarizer(long_text, max_length=50, min_length=10, do_sample=False)\n","print(summary[0]['summary_text'])\n","\n","print(\"\\n>>> YORUM: T5 (Encoder-Decoder), önce Encoder kısmı ile tüm metni okuyup anladı.\")\n","print(\"Ardından Decoder kısmı, bu genel anlayıştan yola çıkarak metnin ana fikrini içeren tamamen yeni ve kısa bir cümle üretti. Bu, bir formattan diğerine dönüşümdür.\")"]},{"cell_type":"markdown","id":"624b68bf","metadata":{"papermill":{"duration":0.017732,"end_time":"2025-07-06T06:35:19.189881","exception":false,"start_time":"2025-07-06T06:35:19.172149","status":"completed"},"tags":[]},"source":["# Uçtan Uca Konular"]},{"cell_type":"code","execution_count":13,"id":"edf8fded","metadata":{"execution":{"iopub.execute_input":"2025-07-06T06:35:19.220772Z","iopub.status.busy":"2025-07-06T06:35:19.219647Z","iopub.status.idle":"2025-07-06T06:36:47.802356Z","shell.execute_reply":"2025-07-06T06:36:47.800883Z"},"papermill":{"duration":88.618689,"end_time":"2025-07-06T06:36:47.823077","exception":false,"start_time":"2025-07-06T06:35:19.204388","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["================================================================================\n","--- AŞAMA 1: Sadece Embedding ile Anlam Yakalamaya Çalışmak (Başarısız Olacak) ---\n","Fikir: Bir cümlenin anlamı, içindeki kelimelerin anlamlarının ortalamasıdır.\n","\n","Girdi: 'he is a student'\n","Çıktı (En Yakın Cümle): 'o bir doktor'\n","\n",">>> KAZANIM/PROBLEM:\n","Bu yöntem, kelimelerin 'anlam torbası' gibi davranır. Kelime sırasını ve grameri tamamen yok sayar.\n","Bu yüzden 'he is a student' gibi bir cümleyi doğru ayırt edemez, çünkü hem 'he is a doctor'\n","hem de 'i am a student' cümlelerine anlamsal olarak benzerdir. Dizilim bilgisini kodlayacak bir yapıya ihtiyacımız var.\n","================================================================================\n","\n","--- AŞAMA 2: Encoder ile Cümle Dizilimini Anlamak ---\n","Fikir: Bir RNN (GRU), cümleyi kelime kelime okuyarak dizilim bilgisini tek bir 'bağlam vektöründe' özetler.\n","\n","Girdi: 'i run fast'\n","Encoder'ın ürettiği 'Anlam Özeti' (Context Vector) boyutu: torch.Size([1, 1, 64])\n","Bu vektör, cümlenin hem kelimelerini hem de onların sırasını içerir.\n","\n",">>> KAZANIM/PROBLEM:\n","Artık elimizde cümlenin sıralı anlamını taşıyan güçlü bir özet var. Ancak bu özetten yola çıkarak\n","nasıl kelime kelime yeni bir cümle 'üretebiliriz'? Bunun için bir üreticiye, yani Decoder'a ihtiyacımız var.\n","================================================================================\n","\n","--- AŞAMA 3: Encoder-Decoder ile Üretken Çeviri ---\n","Fikir: Encoder'ın ürettiği 'anlam özeti', Decoder için bir başlangıç noktasıdır. Decoder, bu özetle başlar ve adım adım yeni bir cümle kurar.\n","\n","Encoder-Decoder modeli eğitiliyor...\n","Eğitim tamamlandı.\n","\n","--- Girdi: 'i run fast' ---\n","1. Encoder girdi cümlesini okudu ve bağlam vektörünü üretti.\n","2. Decoder, bağlam vektörüyle üretime başlıyor:\n","   -> Adım 1: 'ben' kelimesi üretildi.\n","   -> Adım 2: 'hızlı' kelimesi üretildi.\n","   -> Adım 3: 'koşarım' kelimesi üretildi.\n","   -> Adım 4: 'EOS' kelimesi üretildi.\n","Nihai Çıktı: 'ben hızlı koşarım'\n","--- Girdi: 'she is a doctor' ---\n","1. Encoder girdi cümlesini okudu ve bağlam vektörünü üretti.\n","2. Decoder, bağlam vektörüyle üretime başlıyor:\n","   -> Adım 1: 'o' kelimesi üretildi.\n","   -> Adım 2: 'bir' kelimesi üretildi.\n","   -> Adım 3: 'doktor' kelimesi üretildi.\n","   -> Adım 4: 'EOS' kelimesi üretildi.\n","Nihai Çıktı: 'o bir doktor'\n","\n",">>> KAZANIM/PROBLEM:\n","Artık modelimiz sadece en yakın cümleyi bulmuyor, bir cümlenin sıralı anlamını (Encoder ile)\n","kavrayıp bu anlayıştan yola çıkarak kelime kelime, gramer kurallarına uygun yeni bir cümle (Decoder ile) inşa ediyor.\n","Bu, dil işlemede basit benzerlikten gerçek üretkenliğe geçiştir.\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","import random\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","# --- Genel Kurulum ---\n","# Bu kurulum tüm aşamalarda kullanılacak\n","device = torch.device(\"cpu\")\n","SOS_token = 0; EOS_token = 1\n","\n","# Veri setimiz: İngilizce'den Türkçe'ye çeviri çiftleri\n","pairs = [\n","    (\"i am a student\", \"ben bir öğrenciyim\"),\n","    (\"he is a doctor\", \"o bir doktor\"),\n","    (\"they are engineers\", \"onlar mühendis\"),\n","    (\"i run fast\", \"ben hızlı koşarım\"),\n","    (\"she reads a book\", \"o bir kitap okur\")\n","]\n","\n","# Kelime dağarcığı oluşturmak için Lang sınıfı\n","class Lang:\n","    def __init__(self):\n","        self.word2index = {}; self.index2word = {0: \"SOS\", 1: \"EOS\"}; self.n_words = 2\n","    def addSentence(self, sentence):\n","        for word in sentence.split(' '): self.addWord(word)\n","    def addWord(self, word):\n","        if word not in self.word2index:\n","            self.word2index[word] = self.n_words; self.index2word[self.n_words] = word; self.n_words += 1\n","            \n","input_lang = Lang(); output_lang = Lang()\n","for pair in pairs:\n","    input_lang.addSentence(pair[0]); output_lang.addSentence(pair[1])\n","\n","# Hiperparametreler\n","embedding_dim = 64\n","hidden_size = 64\n","\n","# --- AŞAMA 1: Sadece Embedding - \"Anlam Torbası\" Yaklaşımı ---\n","print(\"=\"*80)\n","print(\"--- AŞAMA 1: Sadece Embedding ile Anlam Yakalamaya Çalışmak (Başarısız Olacak) ---\")\n","print(\"Fikir: Bir cümlenin anlamı, içindeki kelimelerin anlamlarının ortalamasıdır.\\n\")\n","\n","# Kelime vektörlerini oluşturmak için bir embedding katmanı\n","embedding_layer = nn.Embedding(input_lang.n_words, embedding_dim)\n","\n","def get_avg_vector(sentence, lang, layer):\n","    \"\"\"Cümlenin ortalama embedding vektörünü hesaplar.\"\"\"\n","    with torch.no_grad():\n","        indices = torch.LongTensor([lang.word2index[w] for w in sentence.split(' ')])\n","        embeddings = layer(indices)\n","        return embeddings.mean(dim=0)\n","\n","# Veri setindeki her cümlenin ortalama vektörünü hesaplayalım\n","input_vectors = [get_avg_vector(pair[0], input_lang, embedding_layer) for pair in pairs]\n","target_vectors = [get_avg_vector(pair[1], output_lang, embedding_layer) for pair in pairs]\n","\n","def translate_with_averaging(sentence, input_vectors, target_sentences):\n","    \"\"\"Girdi cümlesine en çok benzeyen hedef cümleyi bulur.\"\"\"\n","    input_vec = get_avg_vector(sentence, input_lang, embedding_layer).numpy().reshape(1, -1)\n","    # Numpy'a çevirerek benzerlik hesapla\n","    target_vecs_np = torch.stack(target_vectors).numpy()\n","    similarities = cosine_similarity(input_vec, target_vecs_np)\n","    best_match_index = np.argmax(similarities)\n","    return target_sentences[best_match_index]\n","\n","# Test edelim\n","test_sentence_1 = \"he is a student\" # \"he\" ve \"student\" kelimelerini biliyor\n","print(f\"Girdi: '{test_sentence_1}'\")\n","translation = translate_with_averaging(test_sentence_1, input_vectors, [p[1] for p in pairs])\n","print(f\"Çıktı (En Yakın Cümle): '{translation}'\")\n","\n","print(\"\\n>>> KAZANIM/PROBLEM:\")\n","print(\"Bu yöntem, kelimelerin 'anlam torbası' gibi davranır. Kelime sırasını ve grameri tamamen yok sayar.\")\n","print(\"Bu yüzden 'he is a student' gibi bir cümleyi doğru ayırt edemez, çünkü hem 'he is a doctor'\")\n","print(\"hem de 'i am a student' cümlelerine anlamsal olarak benzerdir. Dizilim bilgisini kodlayacak bir yapıya ihtiyacımız var.\")\n","print(\"=\"*80)\n","\n","\n","# --- AŞAMA 2: Encoder'ı Eklemek - Sıralı Anlamı Yoğunlaştırma ---\n","print(\"\\n--- AŞAMA 2: Encoder ile Cümle Dizilimini Anlamak ---\")\n","print(\"Fikir: Bir RNN (GRU), cümleyi kelime kelime okuyarak dizilim bilgisini tek bir 'bağlam vektöründe' özetler.\\n\")\n","\n","class Encoder(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super(Encoder, self).__init__()\n","        self.embedding = nn.Embedding(input_size, hidden_size)\n","        self.gru = nn.GRU(hidden_size, hidden_size)\n","    def forward(self, input, hidden):\n","        embedded = self.embedding(input).view(1, 1, -1)\n","        _, hidden = self.gru(embedded, hidden)\n","        return hidden\n","    def initHidden(self): return torch.zeros(1, 1, hidden_size, device=device)\n","\n","encoder = Encoder(input_lang.n_words, hidden_size)\n","\n","def encode_sentence(sentence, lang, encoder_model):\n","    \"\"\"Bir cümleyi tek bir bağlam vektörüne kodlar.\"\"\"\n","    with torch.no_grad():\n","        indices = torch.LongTensor([lang.word2index[w] for w in sentence.split(' ')])\n","        hidden = encoder_model.initHidden()\n","        for i in range(len(indices)):\n","            # Her kelime sırayla işlenir ve gizli durum güncellenir\n","            hidden = encoder_model(indices[i].unsqueeze(0), hidden)\n","        return hidden\n","\n","# Test edelim\n","test_sentence_2 = \"i run fast\"\n","context_vector = encode_sentence(test_sentence_2, input_lang, encoder)\n","print(f\"Girdi: '{test_sentence_2}'\")\n","print(f\"Encoder'ın ürettiği 'Anlam Özeti' (Context Vector) boyutu: {context_vector.shape}\")\n","print(\"Bu vektör, cümlenin hem kelimelerini hem de onların sırasını içerir.\")\n","\n","print(\"\\n>>> KAZANIM/PROBLEM:\")\n","print(\"Artık elimizde cümlenin sıralı anlamını taşıyan güçlü bir özet var. Ancak bu özetten yola çıkarak\")\n","print(\"nasıl kelime kelime yeni bir cümle 'üretebiliriz'? Bunun için bir üreticiye, yani Decoder'a ihtiyacımız var.\")\n","print(\"=\"*80)\n","\n","\n","# --- AŞAMA 3: Encoder + Decoder - Anlama ve Sıfırdan Üretme ---\n","print(\"\\n--- AŞAMA 3: Encoder-Decoder ile Üretken Çeviri ---\")\n","print(\"Fikir: Encoder'ın ürettiği 'anlam özeti', Decoder için bir başlangıç noktasıdır. Decoder, bu özetle başlar ve adım adım yeni bir cümle kurar.\\n\")\n","\n","class Decoder(nn.Module):\n","    def __init__(self, hidden_size, output_size):\n","        super(Decoder, self).__init__()\n","        self.embedding = nn.Embedding(output_size, hidden_size)\n","        self.gru = nn.GRU(hidden_size, hidden_size)\n","        self.out = nn.Linear(hidden_size, output_size)\n","        self.log_softmax = nn.LogSoftmax(dim=1)\n","    def forward(self, input, hidden):\n","        output = self.embedding(input).view(1, 1, -1); output = torch.relu(output)\n","        output, hidden = self.gru(output, hidden)\n","        output = self.log_softmax(self.out(output[0])); return output, hidden\n","\n","# Eğitim\n","encoder = Encoder(input_lang.n_words, hidden_size)\n","decoder = Decoder(hidden_size, output_lang.n_words)\n","enc_optimizer = optim.SGD(encoder.parameters(), lr=0.01)\n","dec_optimizer = optim.SGD(decoder.parameters(), lr=0.01)\n","criterion = nn.NLLLoss()\n","\n","print(\"Encoder-Decoder modeli eğitiliyor...\")\n","for i in range(10000): # Eğitim iterasyonları\n","    pair = random.choice(pairs)\n","    input_tensor = torch.LongTensor([input_lang.word2index[s] for s in pair[0].split(' ')])\n","    target_tensor = torch.LongTensor([output_lang.word2index[s] for s in pair[1].split(' ')] + [EOS_token])\n","    \n","    # Gerçek eğitim döngüsü (sessiz)\n","    enc_hidden = encoder.initHidden()\n","    enc_optimizer.zero_grad(); dec_optimizer.zero_grad()\n","    loss = 0\n","    for ei in range(len(input_tensor)): enc_hidden = encoder(input_tensor[ei].unsqueeze(0), enc_hidden)\n","    dec_input = torch.tensor([[SOS_token]]); dec_hidden = enc_hidden\n","    for di in range(len(target_tensor)):\n","        dec_output, dec_hidden = decoder(dec_input, dec_hidden)\n","        loss += criterion(dec_output, target_tensor[di].unsqueeze(0)); dec_input = target_tensor[di]\n","    loss.backward(); enc_optimizer.step(); dec_optimizer.step()\n","print(\"Eğitim tamamlandı.\\n\")\n","\n","# Test ve Adım Adım Üretimi Gösterme\n","def translate_with_encoder_decoder(sentence):\n","    print(f\"--- Girdi: '{sentence}' ---\")\n","    with torch.no_grad():\n","        input_tensor = torch.LongTensor([input_lang.word2index[s] for s in sentence.split(' ')])\n","        \n","        # Encoder Aşaması\n","        enc_hidden = encoder.initHidden()\n","        for ei in range(len(input_tensor)):\n","            enc_hidden = encoder(input_tensor[ei].unsqueeze(0), enc_hidden)\n","        print(\"1. Encoder girdi cümlesini okudu ve bağlam vektörünü üretti.\")\n","\n","        # Decoder Aşaması\n","        dec_input = torch.tensor([[SOS_token]])\n","        dec_hidden = enc_hidden\n","        decoded_words = []\n","        print(\"2. Decoder, bağlam vektörüyle üretime başlıyor:\")\n","        for di in range(10): # Maksimum 10 kelime\n","            dec_output, dec_hidden = decoder(dec_input, dec_hidden)\n","            topv, topi = dec_output.data.topk(1)\n","            word = output_lang.index2word[topi.item()]\n","            print(f\"   -> Adım {di+1}: '{word}' kelimesi üretildi.\")\n","            if topi.item() == EOS_token: break\n","            decoded_words.append(word)\n","            dec_input = topi.squeeze().detach().unsqueeze(0)\n","        \n","        print(f\"Nihai Çıktı: '{' '.join(decoded_words)}'\")\n","\n","translate_with_encoder_decoder(\"i run fast\")\n","translate_with_encoder_decoder(\"she is a doctor\")\n","\n","print(\"\\n>>> KAZANIM/PROBLEM:\")\n","print(\"Artık modelimiz sadece en yakın cümleyi bulmuyor, bir cümlenin sıralı anlamını (Encoder ile)\")\n","print(\"kavrayıp bu anlayıştan yola çıkarak kelime kelime, gramer kurallarına uygun yeni bir cümle (Decoder ile) inşa ediyor.\")\n","print(\"Bu, dil işlemede basit benzerlikten gerçek üretkenliğe geçiştir.\")"]},{"cell_type":"markdown","id":"688f09ec","metadata":{"papermill":{"duration":0.011231,"end_time":"2025-07-06T06:36:47.846234","exception":false,"start_time":"2025-07-06T06:36:47.835003","status":"completed"},"tags":[]},"source":["# Embedding, Attention ve Decoder ile Cümle Üretimi"]},{"cell_type":"markdown","id":"4fb7a24b","metadata":{"papermill":{"duration":0.010476,"end_time":"2025-07-06T06:36:47.867418","exception":false,"start_time":"2025-07-06T06:36:47.856942","status":"completed"},"tags":[]},"source":["Bu, öğrendiğimiz tüm kavramları (Embedding, Attention, Decoder) bir araya getirerek, modern bir sohbet robotunun temel \"düşünme\" sürecini gösteren, uçtan uca ve öğretici bir kod örneği olacak.\n","\n","Bu kod, bir soruya cevap üretirken her bir bileşenin ne işe yaradığını ve bir sonraki aşamaya nasıl bir \"kazanım\" sağladığını adım adım ara çıktılarla gösterecek şekilde tasarlanmıştır.\n","\n","**Senaryo ve Anlatım Akışı**\n","\n","Bir soru-cevap chatbot'u yapacağız. Hikayemiz üç aşamadan oluşacak:\n","\n","* Aşama 1: Embedding - Anlam Dünyasına Giriş: Bir cümlenin kelimelerini, makinenin anlayabileceği sayılara (vektörlere) nasıl dönüştürdüğümüzü göreceğiz.\n","\n","* Aşama 2: Attention - Akıllıca Odaklanma: Cevap üretirken, Decoder'ın orijinal sorudaki hangi kelimelere \"daha fazla dikkat etmesi\" gerektiğini nasıl anladığını görselleştireceğiz.\n","\n","* Aşama 3: Decoder - Cümle Kurma Sanatı: Bu odaklanmış bilgiyi alan Decoder'ın, nasıl adım adım tutarlı ve bağlama uygun bir cevap cümlesi inşa ettiğini izleyeceğiz.\n","\n","* Mimari: Bu örnek için, Attention mekanizmasının rolünü en net şekilde gösterebilen Attention'lı Encoder-Decoder (RNN/GRU tabanlı) yapısını kullanacağız."]},{"cell_type":"code","execution_count":14,"id":"d5ee8133","metadata":{"execution":{"iopub.execute_input":"2025-07-06T06:36:47.891876Z","iopub.status.busy":"2025-07-06T06:36:47.891421Z","iopub.status.idle":"2025-07-06T06:39:43.948626Z","shell.execute_reply":"2025-07-06T06:39:43.947615Z"},"papermill":{"duration":176.274586,"end_time":"2025-07-06T06:39:44.152454","exception":false,"start_time":"2025-07-06T06:36:47.877868","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Chatbot modeli eğitiliyor...\n","Eğitim tamamlandı.\n","\n","--- SOHBET BAŞLATILDI (Çıkmak için 'exit' yazın) ---\n","\n","========================================================\n",">>> KULLANICI SORUSU: 'merhaba'\n","========================================================\n","\n","--- AŞAMA 1: EMBEDDING (Anlamı Sayısallaştırma) ---\n","'merhaba' cümlesi, her kelime için 128 boyutlu vektörler içeren bir tensöre dönüştürüldü.\n",">>> KAZANIM: Metin, artık makinenin işleyebileceği bir formata sahip.\n","\n","\n","--- AŞAMA 2 & 3: ATTENTION (Odaklanma) ve DECODER (Üretme) ---\n"," Adım 1:\n","   - ATTENTION: Girdi cümlesindeki kelimelere dikkat odakları:\n","     'merhaba': 0.34 | \n","   >>> KAZANIM: Decoder, şu an üreteceği kelime için sorunun en ilgili kısmına odaklandı.\n","   - DECODER: Odaklanmış bilgiyi kullanarak 'sana' kelimesini üretti.\n","   >>> KAZANIM: Cevap, kelime kelime, bağlama uygun şekilde sıfırdan inşa ediliyor.\n","\n"," Adım 2:\n","   - ATTENTION: Girdi cümlesindeki kelimelere dikkat odakları:\n","     'merhaba': 0.06 | \n","   >>> KAZANIM: Decoder, şu an üreteceği kelime için sorunun en ilgili kısmına odaklandı.\n","   - DECODER: Odaklanmış bilgiyi kullanarak 'basit' kelimesini üretti.\n","   >>> KAZANIM: Cevap, kelime kelime, bağlama uygun şekilde sıfırdan inşa ediliyor.\n","\n"," Adım 3:\n","   - ATTENTION: Girdi cümlesindeki kelimelere dikkat odakları:\n","     'merhaba': 0.21 | \n","   >>> KAZANIM: Decoder, şu an üreteceği kelime için sorunun en ilgili kısmına odaklandı.\n","   - DECODER: Odaklanmış bilgiyi kullanarak 'konularda' kelimesini üretti.\n","   >>> KAZANIM: Cevap, kelime kelime, bağlama uygun şekilde sıfırdan inşa ediliyor.\n","\n"," Adım 4:\n","   - ATTENTION: Girdi cümlesindeki kelimelere dikkat odakları:\n","     'merhaba': 0.03 | \n","   >>> KAZANIM: Decoder, şu an üreteceği kelime için sorunun en ilgili kısmına odaklandı.\n","   - DECODER: Odaklanmış bilgiyi kullanarak 'cevaplar' kelimesini üretti.\n","   >>> KAZANIM: Cevap, kelime kelime, bağlama uygun şekilde sıfırdan inşa ediliyor.\n","\n"," Adım 5:\n","   - ATTENTION: Girdi cümlesindeki kelimelere dikkat odakları:\n","     'merhaba': 0.03 | \n","   >>> KAZANIM: Decoder, şu an üreteceği kelime için sorunun en ilgili kısmına odaklandı.\n","   - DECODER: Odaklanmış bilgiyi kullanarak 'verebilirim' kelimesini üretti.\n","   >>> KAZANIM: Cevap, kelime kelime, bağlama uygun şekilde sıfırdan inşa ediliyor.\n","\n"," Adım 6:\n","   - ATTENTION: Girdi cümlesindeki kelimelere dikkat odakları:\n","     'merhaba': 0.03 | \n","   >>> KAZANIM: Decoder, şu an üreteceği kelime için sorunun en ilgili kısmına odaklandı.\n","   - DECODER: Odaklanmış bilgiyi kullanarak 'EOS' kelimesini üretti.\n","   >>> KAZANIM: Cevap, kelime kelime, bağlama uygun şekilde sıfırdan inşa ediliyor.\n","\n","\n","--------------------------------------------------------\n","Bot Cevabı: sana basit konularda cevaplar verebilirim\n","--------------------------------------------------------\n"]},{"data":{"text/plain":["'\\nwhile True:\\n    try:\\n        user_input = input(\"Siz: \")\\n        if user_input.lower() == \\'exit\\':\\n            break\\n        response, attentions = respond_and_explain(user_input)\\n        print(\"\\n--------------------------------------------------------\")\\n        print(f\"Bot Cevabı: {response}\")\\n        print(\"--------------------------------------------------------\")\\n    except KeyError:\\n        print(\"Bot: Üzgünüm, bu kelimelerden bazılarını bilmiyorum. Başka bir şey sorabilir misin?\")\\n    except Exception as e:\\n        print(f\"Bir hata oluştu: {e}\")\\n'"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import random\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","# --- Adım 0: Kurulum ve Veri Hazırlığı ---\n","device = torch.device(\"cpu\")\n","SOS_token = 0; EOS_token = 1; UNK_token = 2\n","\n","class Lang:\n","    def __init__(self):\n","        self.word2index = {}; self.index2word = {0: \"SOS\", 1: \"EOS\", 2: \"<UNK>\"}; self.n_words = 3\n","    def addSentence(self, sentence):\n","        for word in sentence.split(' '): self.addWord(word)\n","    def addWord(self, word):\n","        if word not in self.word2index:\n","            self.word2index[word] = self.n_words; self.index2word[self.n_words] = word; self.n_words += 1\n","\n","def sentence_to_tensor(lang, sentence):\n","    indexes = [lang.word2index.get(word, UNK_token) for word in sentence.split(' ')]\n","    indexes.append(EOS_token)\n","    return torch.LongTensor(indexes).view(-1, 1).to(device)\n","\n","qa_pairs = [\n","    (\"nasılsın\", \"iyiyim teşekkür ederim sorduğun için\"),\n","    (\"senin adın ne\", \"benim adım yapay zeka sohbet robotu\"),\n","    (\"ne yapabilirsin\", \"sana basit konularda cevaplar verebilirim\"),\n","    (\"hava nasıl bugün\", \"üzgünüm ama hava durumunu henüz bilemiyorum\"),\n","    (\"teşekkür ederim\", \"rica ederim başka bir sorun var mıydı\"),\n","    (\"kaç yaşındasın\", \"ben bir yazılımım benim yaşım olmaz\")\n","]\n","input_lang = Lang(); output_lang = Lang()\n","for q, a in qa_pairs: input_lang.addSentence(q); output_lang.addSentence(a)\n","\n","# --- Modeller (Hata Düzeltildi ve Attention Eklendi) ---\n","hidden_size = 128\n","max_length = 20 # Maksimum cümle uzunluğu\n","\n","# Encoder, cümlenin sıralı anlamını tek bir vektöre kodlar.\n","class EncoderRNN(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super(EncoderRNN, self).__init__()\n","        # HATA DÜZELTİLDİ: self.hidden_size burada tanımlanmalı.\n","        self.hidden_size = hidden_size\n","        self.embedding = nn.Embedding(input_size, hidden_size)\n","        self.gru = nn.GRU(hidden_size, hidden_size)\n","\n","    def forward(self, input, hidden):\n","        embedded = self.embedding(input).view(1, 1, -1)\n","        output, hidden = self.gru(embedded, hidden)\n","        return output, hidden\n","\n","    def initHidden(self): return torch.zeros(1, 1, self.hidden_size, device=device)\n","\n","# AttnDecoderRNN, her adımda Encoder'ın çıktılarına \"dikkat ederek\" yeni kelime üretir.\n","class AttnDecoderRNN(nn.Module):\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n","        super(AttnDecoderRNN, self).__init__()\n","        self.embedding = nn.Embedding(output_size, hidden_size)\n","        self.attention = nn.Linear(hidden_size * 2, max_length)\n","        self.attn_combine = nn.Linear(hidden_size * 2, hidden_size)\n","        self.dropout = nn.Dropout(dropout_p)\n","        self.gru = nn.GRU(hidden_size, hidden_size)\n","        self.out = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, input, hidden, encoder_outputs):\n","        embedded = self.embedding(input).view(1, 1, -1)\n","        embedded = self.dropout(embedded)\n","        \n","        attn_weights = F.softmax(self.attention(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n","        \n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\n","        output = self.attn_combine(output).unsqueeze(0)\n","        output = F.relu(output)\n","        \n","        output, hidden = self.gru(output, hidden)\n","        output = F.log_softmax(self.out(output[0]), dim=1)\n","        return output, hidden, attn_weights\n","\n","# --- Eğitim Fonksiyonu ---\n","def train(inp_t, tar_t, enc, dec, enc_opt, dec_opt, crit):\n","    enc_h = enc.initHidden(); enc_opt.zero_grad(); dec_opt.zero_grad(); loss=0\n","    enc_outs = torch.zeros(max_length, enc.hidden_size, device=device)\n","    for ei in range(len(inp_t)):\n","        enc_out, enc_h = enc(inp_t[ei], enc_h)\n","        enc_outs[ei] = enc_out[0, 0]\n","        \n","    dec_i=torch.tensor([[SOS_token]], device=device); dec_h=enc_h\n","    for di in range(len(tar_t)):\n","        dec_o, dec_h, _ = dec(dec_i, dec_h, enc_outs)\n","        loss += crit(dec_o, tar_t[di]); dec_i = tar_t[di]\n","        if dec_i.item() == EOS_token: break\n","    loss.backward(); enc_opt.step(); dec_opt.step()\n","    return loss.item() / len(tar_t)\n","\n","# --- Eğitim ---\n","encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n","decoder = AttnDecoderRNN(hidden_size, output_lang.n_words).to(device)\n","encoder_optimizer = optim.SGD(encoder.parameters(), lr=0.01)\n","decoder_optimizer = optim.SGD(decoder.parameters(), lr=0.01)\n","criterion = nn.NLLLoss()\n","\n","print(\"Chatbot modeli eğitiliyor...\")\n","for i in range(10000): # Eğitim iterasyonları\n","    pair = random.choice(qa_pairs)\n","    input_tensor = sentence_to_tensor(input_lang, pair[0])\n","    target_tensor = sentence_to_tensor(output_lang, pair[1])\n","    train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n","print(\"Eğitim tamamlandı.\")\n","\n","\n","# --- UÇTAN UCA GÖSTERİM FONKSİYONU ---\n","def respond_and_explain(sentence):\n","    print(f\"\\n========================================================\")\n","    print(f\">>> KULLANICI SORUSU: '{sentence}'\")\n","    print(\"========================================================\")\n","    with torch.no_grad():\n","        # --- AŞAMA 1: EMBEDDING ---\n","        print(\"\\n--- AŞAMA 1: EMBEDDING (Anlamı Sayısallaştırma) ---\")\n","        input_tensor = sentence_to_tensor(input_lang, sentence)\n","        embedded_vectors = encoder.embedding(input_tensor).squeeze(1)\n","        print(f\"'{sentence}' cümlesi, her kelime için {hidden_size} boyutlu vektörler içeren bir tensöre dönüştürüldü.\")\n","        print(\">>> KAZANIM: Metin, artık makinenin işleyebileceği bir formata sahip.\\n\")\n","        \n","        # Encoder\n","        encoder_hidden = encoder.initHidden()\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n","        for ei in range(len(input_tensor)):\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n","            encoder_outputs[ei] = encoder_output[0, 0]\n","            \n","        # Decoder\n","        decoder_input = torch.tensor([[SOS_token]], device=device)\n","        decoder_hidden = encoder_hidden\n","        decoded_words = []\n","        decoder_attentions = torch.zeros(max_length, max_length)\n","\n","        print(\"\\n--- AŞAMA 2 & 3: ATTENTION (Odaklanma) ve DECODER (Üretme) ---\")\n","        for di in range(max_length):\n","            # Her adımda Attention ve Decoder birlikte çalışır\n","            decoder_output, decoder_hidden, attn_weights = decoder(decoder_input, decoder_hidden, encoder_outputs)\n","            \n","            # --- ARA ÇIKTILAR ---\n","            decoder_attentions[di] = attn_weights.data\n","            topv, topi = decoder_output.data.topk(1)\n","            word_index = topi.item()\n","            \n","            print(f\" Adım {di+1}:\")\n","            # AŞAMA 2'NİN KAZANIMI\n","            print(\"   - ATTENTION: Girdi cümlesindeki kelimelere dikkat odakları:\")\n","            attention_slice = attn_weights.squeeze(0).squeeze(0).numpy()\n","            for i, word in enumerate(sentence.split(' ')):\n","                print(f\"     '{word}': {attention_slice[i]:.2f}\", end=\" | \")\n","            print(\"\\n   >>> KAZANIM: Decoder, şu an üreteceği kelime için sorunun en ilgili kısmına odaklandı.\")\n","            \n","            # AŞAMA 3'ÜN KAZANIMI\n","            word = output_lang.index2word[word_index]\n","            print(f\"   - DECODER: Odaklanmış bilgiyi kullanarak '{word}' kelimesini üretti.\")\n","            print(f\"   >>> KAZANIM: Cevap, kelime kelime, bağlama uygun şekilde sıfırdan inşa ediliyor.\\n\")\n","            \n","            if word_index == EOS_token: break\n","            decoded_words.append(word)\n","            decoder_input = topi.squeeze().detach()\n","\n","        return ' '.join(decoded_words), decoder_attentions[:di + 1, :len(sentence.split(' '))]\n","\n","# --- İnteraktif Sohbet ---\n","print(\"\\n--- SOHBET BAŞLATILDI (Çıkmak için 'exit' yazın) ---\")\n","user_input = \"merhaba\"\n","response, attentions = respond_and_explain(user_input)\n","print(\"\\n--------------------------------------------------------\")\n","print(f\"Bot Cevabı: {response}\")\n","print(\"--------------------------------------------------------\")\n","'''\n","while True:\n","    try:\n","        user_input = input(\"Siz: \")\n","        if user_input.lower() == 'exit':\n","            break\n","        response, attentions = respond_and_explain(user_input)\n","        print(\"\\n--------------------------------------------------------\")\n","        print(f\"Bot Cevabı: {response}\")\n","        print(\"--------------------------------------------------------\")\n","    except KeyError:\n","        print(\"Bot: Üzgünüm, bu kelimelerden bazılarını bilmiyorum. Başka bir şey sorabilir misin?\")\n","    except Exception as e:\n","        print(f\"Bir hata oluştu: {e}\")\n","'''"]},{"cell_type":"code","execution_count":15,"id":"242b0403","metadata":{"execution":{"iopub.execute_input":"2025-07-06T06:39:44.177333Z","iopub.status.busy":"2025-07-06T06:39:44.176933Z","iopub.status.idle":"2025-07-06T06:45:09.978938Z","shell.execute_reply":"2025-07-06T06:45:09.977896Z"},"papermill":{"duration":325.830458,"end_time":"2025-07-06T06:45:09.994704","exception":false,"start_time":"2025-07-06T06:39:44.164246","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["================================================================================\n","--- Bot 1: 'Kelime Avcısı' (Sadece Embedding Yeteneği) ---\n","\n","================================================================================\n","--- Bot 2 ve Bot 3 için Modeller Eğitiliyor ---\n","Eğitimler tamamlandı.\n","\n","================================================================================\n","--- MODELLERİN KARŞILAŞTIRILMASI ---\n","\n","[Bot 1] Kullanıcı Sorusu: 'en sevdiğin renk ne olabilir'\n","[Bot 1] Cevap (Hazır Cevaplardan Seçim): 'bir yazılım olarak renkleri göremem'\n","\n",">>> KAZANIM: Embedding'in temel fikri olan kelime eşleştirme sayesinde basit bir cevap bulabildik.\n",">>> EKSİKLİK: Cümle yapısı, gramer veya bağlam tamamen yok sayıldı. Yeni bir cümle kuramıyor, sadece ezberindekini tekrar ediyor.\n","\n","[Bot 2] Kullanıcı Sorusu: 'en sevdiğin renk ne olabilir'\n","[Bot 2] Cevap (Attention'sız Encoder-Decoder): 'bir yazılım olarak renkleri göremem'\n","\n",">>> KAZANIM: Artık ezberlemiyor, kelime kelime yeni bir cümle üretiyoruz.\n",">>> EKSİKLİK: Cümle uzun olduğunda, Encoder'ın ürettiği tek bir 'özet vektörü' yetersiz kalıyor. Model, cümlenin başındaki 'renk' gibi önemli bir detayı unutabiliyor ve genel bir cevap veriyor.\n","\n","[Bot 3] Kullanıcı Sorusu: 'en sevdiğin renk ne olabilir'\n","Not: Yaratıcılık için Temperature Sampling kullanıldığından, her seferinde biraz farklı cevaplar alabilirsiniz.\n","[Bot 3] Cevap (Attention'lı Encoder-Decoder): 'bir yazılım olarak renkleri göremem'\n","\n",">>> KAZANIM: Attention sayesinde Decoder, cevabı üretirken sorunun en kilit kısmına ('renk' kelimesine) odaklanabildi ve bu sayede çok daha isabetli bir cevap üretti.\n",">>> KAZANIM: Sıcaklık (temperature) parametresi, modele deterministik olmak yerine olasılıksal ve yaratıcı cevaplar üretme yeteneği kazandırdı.\n","\n","================================================================================\n","SONUÇ: Embedding ile başladık, Encoder-Decoder ile cümle kurmayı öğrendik ve son olarak Attention ile bu yeteneği akıllı ve odaklı hale getirdik.\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import random\n","import torch.nn.functional as F\n","import numpy as np\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","# --- Genel Kurulum ---\n","device = torch.device(\"cpu\")\n","SOS_token = 0; EOS_token = 1; UNK_token = 2\n","\n","# Daha uzun ve çeşitli cümleler içeren veri seti\n","qa_pairs = [\n","    (\"nasılsın\", \"iyiyim teşekkür ederim sorduğun için\"),\n","    (\"senin adın ne\", \"benim adım yapay zeka sohbet robotu\"),\n","    (\"ne yapabilirsin\", \"sana basit konularda doğru cevaplar verebilirim\"),\n","    (\"bugün hava nasıl\", \"üzgünüm ama hava durumunu henüz bilemiyorum\"),\n","    (\"en sevdiğin renk ne\", \"bir yazılım olarak renkleri göremem\"),\n","    (\"bana bir şaka anlat\", \"neden yapay zeka hiç kaybolmaz çünkü her zaman evdeki sunucusuna döner\"),\n","    (\"teşekkürler\", \"rica ederim başka bir sorun var mıydı\")\n","]\n","\n","class Lang:\n","    def __init__(self): self.word2index = {}; self.index2word = {0:\"SOS\", 1:\"EOS\", 2:\"<UNK>\"}; self.n_words = 3\n","    def addSentence(self, sentence):\n","        for word in sentence.split(' '): self.addWord(word)\n","    def addWord(self, word):\n","        if word not in self.word2index: self.word2index[word]=self.n_words; self.index2word[self.n_words]=word; self.n_words+=1\n","\n","input_lang = Lang(); output_lang = Lang()\n","for q, a in qa_pairs: input_lang.addSentence(q); output_lang.addSentence(a)\n","\n","def sentence_to_tensor(lang, sentence):\n","    indexes = [lang.word2index.get(word, UNK_token) for word in sentence.split(' ')]\n","    indexes.append(EOS_token)\n","    return torch.LongTensor(indexes).view(-1, 1).to(device)\n","\n","# --- AŞAMA 1: Sadece Embedding Kullanan \"Kelime Avcısı\" Bot ---\n","print(\"=\"*80)\n","print(\"--- Bot 1: 'Kelime Avcısı' (Sadece Embedding Yeteneği) ---\")\n","\n","def simple_keyword_bot(user_input, qa_database):\n","    print(f\"\\n[Bot 1] Kullanıcı Sorusu: '{user_input}'\")\n","    input_words = set(user_input.split(' '))\n","    best_match_score = 0\n","    best_answer = \"Üzgünüm, bu konuda bir bilgim yok.\"\n","\n","    for question, answer in qa_database:\n","        question_words = set(question.split(' '))\n","        match_score = len(input_words.intersection(question_words))\n","        if match_score > best_match_score:\n","            best_match_score = match_score\n","            best_answer = answer\n","            \n","    print(f\"[Bot 1] Cevap (Hazır Cevaplardan Seçim): '{best_answer}'\")\n","    print(\"\\n>>> KAZANIM: Embedding'in temel fikri olan kelime eşleştirme sayesinde basit bir cevap bulabildik.\")\n","    print(\">>> EKSİKLİK: Cümle yapısı, gramer veya bağlam tamamen yok sayıldı. Yeni bir cümle kuramıyor, sadece ezberindekini tekrar ediyor.\")\n","\n","# --- AŞAMA 2 & 3 için Ortak Modeller ---\n","hidden_size = 128\n","max_length = 25\n","\n","class Encoder(nn.Module):\n","    def __init__(self, i_s, h_s): super(Encoder, self).__init__(); self.h_s=h_s; self.emb=nn.Embedding(i_s,h_s); self.gru=nn.GRU(h_s,h_s)\n","    def forward(self, i, h): e=self.emb(i).view(1,1,-1); o,h=self.gru(e,h); return o,h\n","    def initHidden(self): return torch.zeros(1, 1, self.h_s, device=device)\n","\n","class Decoder(nn.Module): # Attention'SIZ Decoder\n","    def __init__(self, h_s, o_s): super(Decoder, self).__init__(); self.emb=nn.Embedding(o_s,h_s); self.gru=nn.GRU(h_s,h_s); self.out=nn.Linear(h_s,o_s); self.softmax=nn.LogSoftmax(dim=1)\n","    def forward(self, i, h): o=self.emb(i).view(1,1,-1); o=F.relu(o); o,h=self.gru(o,h); o=self.softmax(self.out(o[0])); return o,h\n","    \n","class AttnDecoder(nn.Module): # Attention'LI Decoder\n","    def __init__(self, h_s, o_s, dropout_p=0.1):\n","        super(AttnDecoder, self).__init__(); self.emb=nn.Embedding(o_s,h_s); self.attn=nn.Linear(h_s*2,max_length); self.attn_combine=nn.Linear(h_s*2,h_s); self.dropout=nn.Dropout(dropout_p); self.gru=nn.GRU(h_s,h_s); self.out=nn.Linear(h_s,o_s)\n","    def forward(self, i, h, enc_outs):\n","        e=self.emb(i).view(1,1,-1); e=self.dropout(e)\n","        aw=F.softmax(self.attn(torch.cat((e[0],h[0]),1)),dim=1); aa=torch.bmm(aw.unsqueeze(0),enc_outs.unsqueeze(0))\n","        o=torch.cat((e[0],aa[0]),1); o=self.attn_combine(o).unsqueeze(0); o=F.relu(o)\n","        o,h=self.gru(o,h); o=F.log_softmax(self.out(o[0]),dim=1); return o,h,aw\n","\n","# Eğitim fonksiyonu\n","def train_seq2seq(inp_t, tar_t, enc, dec, enc_opt, dec_opt, crit, use_attention=False):\n","    enc_h=enc.initHidden(); enc_opt.zero_grad(); dec_opt.zero_grad(); loss=0\n","    enc_outs=torch.zeros(max_length,enc.h_s,device=device)\n","    for ei in range(len(inp_t)): enc_o,enc_h = enc(inp_t[ei],enc_h); enc_outs[ei]=enc_o[0,0]\n","    dec_i=torch.tensor([[SOS_token]],device=device); dec_h=enc_h\n","    for di in range(len(tar_t)):\n","        if use_attention: dec_o, dec_h, _ = dec(dec_i, dec_h, enc_outs)\n","        else: dec_o, dec_h = dec(dec_i, dec_h)\n","        loss+=crit(dec_o,tar_t[di]); dec_i=tar_t[di]\n","        if dec_i.item() == EOS_token: break\n","    loss.backward(); enc_opt.step(); dec_opt.step()\n","\n","# Değerlendirme fonksiyonu\n","def evaluate(sentence, enc, dec, use_attention=False, temperature=0.5):\n","    with torch.no_grad():\n","        inp_t=sentence_to_tensor(input_lang,sentence); enc_h=enc.initHidden()\n","        enc_outs=torch.zeros(max_length,enc.h_s,device=device)\n","        for ei in range(len(inp_t)): enc_o,enc_h=enc(inp_t[ei],enc_h); enc_outs[ei]=enc_o[0,0]\n","        dec_i=torch.tensor([[SOS_token]],device=device); dec_h=enc_h\n","        decoded_words=[]\n","        for di in range(max_length):\n","            if use_attention: dec_o,dec_h,_ = dec(dec_i,dec_h,enc_outs)\n","            else: dec_o,dec_h = dec(dec_i,dec_h)\n","            \n","            # YARATICILIK İÇİN TEMPERATURE SAMPLING\n","            decoder_output_dist = dec_o.div(temperature).exp()\n","            topi = torch.multinomial(decoder_output_dist, 1)[0]\n","            \n","            if topi.item() == EOS_token: break\n","            else: decoded_words.append(output_lang.index2word[topi.item()])\n","            dec_i = topi.squeeze().detach()\n","        return ' '.join(decoded_words)\n","\n","# --- Bot 2 ve 3 için Eğitim ---\n","print(\"\\n\" + \"=\"*80)\n","print(\"--- Bot 2 ve Bot 3 için Modeller Eğitiliyor ---\")\n","# Bot 2 Modelleri (Attention'sız)\n","encoder2 = Encoder(input_lang.n_words, hidden_size).to(device)\n","decoder2 = Decoder(hidden_size, output_lang.n_words).to(device)\n","enc2_opt = optim.SGD(encoder2.parameters(), lr=0.01); dec2_opt = optim.SGD(decoder2.parameters(), lr=0.01)\n","\n","# Bot 3 Modelleri (Attention'lı)\n","encoder3 = Encoder(input_lang.n_words, hidden_size).to(device)\n","decoder3 = AttnDecoder(hidden_size, output_lang.n_words).to(device)\n","enc3_opt = optim.SGD(encoder3.parameters(), lr=0.01); dec3_opt = optim.SGD(decoder3.parameters(), lr=0.01)\n","\n","criterion = nn.NLLLoss()\n","for i in range(10000):\n","    pair = random.choice(qa_pairs)\n","    inp_t = sentence_to_tensor(input_lang, pair[0]); tar_t = sentence_to_tensor(output_lang, pair[1])\n","    train_seq2seq(inp_t,tar_t,encoder2,decoder2,enc2_opt,dec2_opt,criterion,use_attention=False)\n","    train_seq2seq(inp_t,tar_t,encoder3,decoder3,enc3_opt,dec3_opt,criterion,use_attention=True)\n","print(\"Eğitimler tamamlandı.\")\n","\n","# --- KARŞILAŞTIRMALI TEST ---\n","print(\"\\n\" + \"=\"*80)\n","print(\"--- MODELLERİN KARŞILAŞTIRILMASI ---\")\n","\n","# Uzun ve detaylı bir soru seçelim\n","test_sentence = \"en sevdiğin renk ne olabilir\"\n","\n","# --- Bot 1'in Cevabı ---\n","simple_keyword_bot(test_sentence, qa_pairs)\n","\n","# --- Bot 2'nin Cevabı ---\n","print(f\"\\n[Bot 2] Kullanıcı Sorusu: '{test_sentence}'\")\n","response2 = evaluate(test_sentence, encoder2, decoder2, use_attention=False)\n","print(f\"[Bot 2] Cevap (Attention'sız Encoder-Decoder): '{response2}'\")\n","print(\"\\n>>> KAZANIM: Artık ezberlemiyor, kelime kelime yeni bir cümle üretiyoruz.\")\n","print(\">>> EKSİKLİK: Cümle uzun olduğunda, Encoder'ın ürettiği tek bir 'özet vektörü' yetersiz kalıyor. Model, cümlenin başındaki 'renk' gibi önemli bir detayı unutabiliyor ve genel bir cevap veriyor.\")\n","\n","# --- Bot 3'ün Cevabı ---\n","print(f\"\\n[Bot 3] Kullanıcı Sorusu: '{test_sentence}'\")\n","print(\"Not: Yaratıcılık için Temperature Sampling kullanıldığından, her seferinde biraz farklı cevaplar alabilirsiniz.\")\n","response3 = evaluate(test_sentence, encoder3, decoder3, use_attention=True, temperature=0.7)\n","print(f\"[Bot 3] Cevap (Attention'lı Encoder-Decoder): '{response3}'\")\n","print(\"\\n>>> KAZANIM: Attention sayesinde Decoder, cevabı üretirken sorunun en kilit kısmına ('renk' kelimesine) odaklanabildi ve bu sayede çok daha isabetli bir cevap üretti.\")\n","print(\">>> KAZANIM: Sıcaklık (temperature) parametresi, modele deterministik olmak yerine olasılıksal ve yaratıcı cevaplar üretme yeteneği kazandırdı.\")\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"SONUÇ: Embedding ile başladık, Encoder-Decoder ile cümle kurmayı öğrendik ve son olarak Attention ile bu yeteneği akıllı ve odaklı hale getirdik.\")"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"papermill":{"default_parameters":{},"duration":1036.928015,"end_time":"2025-07-06T06:45:12.832482","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-07-06T06:27:55.904467","version":"2.6.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"01fd949b86f24a28a51b95fd668bb49c":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"056ad95d31bb48d79e7be3960a0d1b1e":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"05eb8cdee14b4bd3a7b0dc324d08b45a":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_9a8a14c87802431899a9288ae13c18e6","max":1.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_056ad95d31bb48d79e7be3960a0d1b1e","tabbable":null,"tooltip":null,"value":1.0}},"06bcc31cb649401fb7b11cb82e302636":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08baa28a20ac481e9f7471632a47e6d7":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"09066d6cbdb2471fbbeda6c6c7dc6696":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a59ae05100c4398934a25a42d7b1210":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"0bc6a34cc6a84375b4593222604fafd6":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"0c32af5f4f6943ffa6c2d90a21711ab7":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_2754516a7d1c4425b706bbb6ea9a6257","max":537.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_4d05ec743754407ba2cb39f2ffdaa780","tabbable":null,"tooltip":null,"value":537.0}},"0c644d2a2e2b4e9cbde44732928e840b":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"0e8f9d14d5d6480c93b26dc802ffaed0":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ace0176c2528441c860e5759dd95689b","IPY_MODEL_5967784a71544d98b53877e8f552074c","IPY_MODEL_2de958b068b0497cac00ae75b8fc2491"],"layout":"IPY_MODEL_4236488b680649aebc3dc423408387f6","tabbable":null,"tooltip":null}},"13de6c20afcf4039893eb970ce9fe965":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_c35c40edfe904bfe89a536aad5d630b7","placeholder":"​","style":"IPY_MODEL_08baa28a20ac481e9f7471632a47e6d7","tabbable":null,"tooltip":null,"value":" 132/132 [00:00&lt;00:00, 12.5kB/s]"}},"1589771b9cd142999992fcf133ab3282":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15c0743e0bce44eaaaf830558c446e6e":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16db18e8ee994a3096d4cc91a0f6a62c":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b05fe65b685416086983c96a0c8b058":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b60e7af1fcd4406b0e42b3753789dd7":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_6226db3fe80547b1bd2ac65ae5327fb8","placeholder":"​","style":"IPY_MODEL_bfbfd959dc0e4d4a8d338a79a52f25d1","tabbable":null,"tooltip":null,"value":"model.safetensors: 100%"}},"1be396946e9043589edde68dcdd3ec66":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_f59052039f52458b8367982bac9bbe7c","max":497774208.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_4edac32a2c8f43f8a5fb7f05998179cd","tabbable":null,"tooltip":null,"value":497774208.0}},"1e01dd2d20884d5db2d0d4a782ca7f7d":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f8556b59e3e448c9b75a09c15dfc573":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"218b16ff365449e9a186319909172dad":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23858fdfe0c54251a58296e298b466f9":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"264e3763c15347b6ae920a4444877a4c":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_34b72209d83c4e38939cdb2bae7b0275","placeholder":"​","style":"IPY_MODEL_6af5f6e6a9e54e178cffa7b021e66152","tabbable":null,"tooltip":null,"value":" 498M/498M [00:01&lt;00:00, 294MB/s]"}},"267c9323a4ba4b499b18b906c07d8c6f":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26bc47301b6b4a7e8fc59eb2099ce984":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e0ee010f0e1d4c75a57efd4c2d3f419f","IPY_MODEL_af219e3a675e4ff7aa16b9bb5808be63","IPY_MODEL_ee053dceebc94e3ea95ebe8c67564865"],"layout":"IPY_MODEL_8c78e9010ab0403f9593cbec48e80965","tabbable":null,"tooltip":null}},"2754516a7d1c4425b706bbb6ea9a6257":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2991bb9a23434ed3a2e38d5748cabbcc":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a97be1674b046df85f76d0210f80846":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"2de958b068b0497cac00ae75b8fc2491":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_3253d5a5da6b4d0a838bf17d8979913c","placeholder":"​","style":"IPY_MODEL_6cfc1014ca2f4fd881dbc08ebacf72fa","tabbable":null,"tooltip":null,"value":" 438/438 [00:00&lt;00:00, 49.1kB/s]"}},"2f3c93a1df7f487b962c7dc74e6e2c66":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_dbb83a7867c74ebba0c913247577a7ce","placeholder":"​","style":"IPY_MODEL_62e816997ae94cd4931628424fa88a4e","tabbable":null,"tooltip":null,"value":" 1.39M/? [00:00&lt;00:00, 25.1MB/s]"}},"2f6c35816fbc4d9ab03df2c400de4694":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1b60e7af1fcd4406b0e42b3753789dd7","IPY_MODEL_1be396946e9043589edde68dcdd3ec66","IPY_MODEL_264e3763c15347b6ae920a4444877a4c"],"layout":"IPY_MODEL_8e856684dd084a9db9c13df67117afec","tabbable":null,"tooltip":null}},"3253d5a5da6b4d0a838bf17d8979913c":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32df99900b9f4d61b3ca7face0ab1934":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_7e2561156485464b94b7438c6e7ccb0b","max":1.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_3d8df50a394a40b48cd5fcb64e5d5fe7","tabbable":null,"tooltip":null,"value":1.0}},"34b72209d83c4e38939cdb2bae7b0275":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35ad873b2a12440bb22efd08abc797b4":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_e5a1a7e5253c4c52a010a95c6f246539","max":1.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_cce387c0ca5a40fb99a6ffc108d9fb70","tabbable":null,"tooltip":null,"value":1.0}},"360cead321da467794664fb44dc6afe4":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"37593f386f3c439899d321129acef125":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4014da38eadd4fd7960a3cdb63b39217","IPY_MODEL_05eb8cdee14b4bd3a7b0dc324d08b45a","IPY_MODEL_9f32a4bf4a9c4fedb4fc1112279fb6ac"],"layout":"IPY_MODEL_bf0c06a3ded845988135cd662dc5740a","tabbable":null,"tooltip":null}},"37b86104de954fb2a3b7803eeea6e16f":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_0a59ae05100c4398934a25a42d7b1210","max":1.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_d8165edb719e423f9f103cf676855fa3","tabbable":null,"tooltip":null,"value":1.0}},"3c697f984ca54430b5eddf918f8279bf":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3cf186a5cde2461184c7bfc5e4b21e3f":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_06bcc31cb649401fb7b11cb82e302636","placeholder":"​","style":"IPY_MODEL_4e197d92e8f8414eafa16c8424d93687","tabbable":null,"tooltip":null,"value":"merges.txt: "}},"3d098dec17624f2d956bde7c42ac57b6":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_8e816eb265ff47c5b8cd1064ae66e560","placeholder":"​","style":"IPY_MODEL_f77b0afcebbd47e19d8f443b0c457285","tabbable":null,"tooltip":null,"value":"config.json: "}},"3d8df50a394a40b48cd5fcb64e5d5fe7":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3e22f7618a274bfebd1eafdac3a301d0":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"3f55d83810224a51940fa60ee99ff7d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8f1a74f702fb40eca986f6be1794aa7d","IPY_MODEL_4adac615b6e84bef8d47298ff4b2f7fa","IPY_MODEL_2f3c93a1df7f487b962c7dc74e6e2c66"],"layout":"IPY_MODEL_b93be011867d4e6a8c1c8d91dbc65002","tabbable":null,"tooltip":null}},"4014da38eadd4fd7960a3cdb63b39217":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_1b05fe65b685416086983c96a0c8b058","placeholder":"​","style":"IPY_MODEL_2a97be1674b046df85f76d0210f80846","tabbable":null,"tooltip":null,"value":"vocab.txt: "}},"4236488b680649aebc3dc423408387f6":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4249d86a58cb403c9149d32fde9bb01e":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"42e253a7e8c142a385ce42aa9196250a":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_770979a4bd08446490c016aad05b73ff","placeholder":"​","style":"IPY_MODEL_58dc5035b2e34a829ef9b50bbb8c17b2","tabbable":null,"tooltip":null,"value":" 60.0/60.0 [00:00&lt;00:00, 4.70kB/s]"}},"4373ef834a03415cbbe3077345abed91":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_84f1dfc75a094fb5bc3c0a50d1e8cb43","IPY_MODEL_bdf7ffd3a19e433a8957c315529c3990","IPY_MODEL_8f2546a947934aa68eba34ea22a30995"],"layout":"IPY_MODEL_bf115e6275a7453db598bafe7f7ab746","tabbable":null,"tooltip":null}},"43a25290e8d14ec3b02e1513a0a41b57":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_218b16ff365449e9a186319909172dad","max":385.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_7e2e1c289be7488594254ebddb1f66bc","tabbable":null,"tooltip":null,"value":385.0}},"46ed6d286a5d460fb5685ddd1ffc4775":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_721012dde63c4267b306f1f77af02974","IPY_MODEL_97ad04444683492285aa7c4bbfbad1b2","IPY_MODEL_42e253a7e8c142a385ce42aa9196250a"],"layout":"IPY_MODEL_1e01dd2d20884d5db2d0d4a782ca7f7d","tabbable":null,"tooltip":null}},"488d69f055e44d3ba882b72211f07a97":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_991d4b2d4cfb4e599cf90d3ac5be8f09","IPY_MODEL_37b86104de954fb2a3b7803eeea6e16f","IPY_MODEL_8c9ac2a1bde249d68f64b4cabe13cb92"],"layout":"IPY_MODEL_873e6a739954453f917d0c20e2225191","tabbable":null,"tooltip":null}},"4891e5ad411b4623addcf6a376e3c10a":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"4a51ea4d74af4fe5a960172b95fec56d":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4adac615b6e84bef8d47298ff4b2f7fa":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_4891e5ad411b4623addcf6a376e3c10a","max":1.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_52c9e7c8dd4b4c34920592e61e585c67","tabbable":null,"tooltip":null,"value":1.0}},"4cc4200dfc9340f1bb626829649d8e4b":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_cad577edb3e847308e7be471dbeb6f7f","placeholder":"​","style":"IPY_MODEL_937829ac6a08404c855a499bc784198f","tabbable":null,"tooltip":null,"value":"model.safetensors: 100%"}},"4d05ec743754407ba2cb39f2ffdaa780":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4db1cf6455cc403f939f7e896020ce54":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_f03af3b94df04614b9d55d3ec649bc4e","placeholder":"​","style":"IPY_MODEL_a3ff9a31564e48f5b7af4de5d0f95a80","tabbable":null,"tooltip":null,"value":" 892M/892M [00:07&lt;00:00, 149MB/s]"}},"4e197d92e8f8414eafa16c8424d93687":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"4edac32a2c8f43f8a5fb7f05998179cd":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4f7e14be10a948febb81a2d5ee0fa3b1":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9f981f3a02e24346abbf819020cb2e91","IPY_MODEL_89849686704540919354d6f59a1b311f","IPY_MODEL_a1d4415524ea42b7a2c7d5876a07ccf0"],"layout":"IPY_MODEL_50210104c5e349e7b468a6b7ade4abe2","tabbable":null,"tooltip":null}},"50210104c5e349e7b468a6b7ade4abe2":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"522bb04eb82d400699748c1cc257ad2e":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52c9e7c8dd4b4c34920592e61e585c67":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"570372a037664330920f767703717bfc":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d50ad7115dcd45e3a535b3dd77785f9b","IPY_MODEL_0c32af5f4f6943ffa6c2d90a21711ab7","IPY_MODEL_8666d9df178240ceb6f1d81e8c716dcb"],"layout":"IPY_MODEL_5a4cefd4fa7a4a6d914a368b1f2706fe","tabbable":null,"tooltip":null}},"58dc5035b2e34a829ef9b50bbb8c17b2":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"591bc91c41c440ea8c04152c9a56483c":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"5967784a71544d98b53877e8f552074c":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_68ced598255b48018452c44386f72e60","max":438.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_af642622bd774b348b7307436e8aaca6","tabbable":null,"tooltip":null,"value":438.0}},"5a4cefd4fa7a4a6d914a368b1f2706fe":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b7f63116c1746768f0ee352cd296b0f":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f3116eb259f493589601991ac3a635e":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6226db3fe80547b1bd2ac65ae5327fb8":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62e816997ae94cd4931628424fa88a4e":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"68ced598255b48018452c44386f72e60":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a5e2476cce84ac0b1cec8ddebba0bf1":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"6af5f6e6a9e54e178cffa7b021e66152":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"6cfc1014ca2f4fd881dbc08ebacf72fa":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"6f00d55aad724dfaa9925ab5e48b6f93":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_5b7f63116c1746768f0ee352cd296b0f","placeholder":"​","style":"IPY_MODEL_c4b7511021ea43f59b66b6b5bc497b7e","tabbable":null,"tooltip":null,"value":"config.json: 100%"}},"721012dde63c4267b306f1f77af02974":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_ca8dacb5ac934895801ef46131aa122e","placeholder":"​","style":"IPY_MODEL_c7097c3939654be79e7dd91f34d34c30","tabbable":null,"tooltip":null,"value":"tokenizer_config.json: 100%"}},"721f5ad5e42640b6b74248dec02c5137":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"73b4748328354aefae10f3d38613de13":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"75c8792a47384f599730954bbba40047":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"770979a4bd08446490c016aad05b73ff":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"788c950f684a48fbb7257b4298651ebf":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7aea3d9620904e4ea581361121d4f54d":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"7be48b4353494584afdc65671c489a7a":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7e2561156485464b94b7438c6e7ccb0b":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"7e2e1c289be7488594254ebddb1f66bc":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"81ece22a38c84238ba58c6ae8f4f6549":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"84f1dfc75a094fb5bc3c0a50d1e8cb43":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_cbc6210bbf1347658159e88b70f1af8e","placeholder":"​","style":"IPY_MODEL_1f8556b59e3e448c9b75a09c15dfc573","tabbable":null,"tooltip":null,"value":"generation_config.json: 100%"}},"8666d9df178240ceb6f1d81e8c716dcb":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_d3e031525a1c4d5d9b1e30ce6a8ca7f6","placeholder":"​","style":"IPY_MODEL_6a5e2476cce84ac0b1cec8ddebba0bf1","tabbable":null,"tooltip":null,"value":" 537/537 [00:00&lt;00:00, 49.2kB/s]"}},"870ca376e05e4de2bec9ea7fc71f5d5c":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"873e6a739954453f917d0c20e2225191":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88c5c18de66c4e519f282c1c71ba2594":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"89849686704540919354d6f59a1b311f":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_3c697f984ca54430b5eddf918f8279bf","max":791656.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_b0b584c5704e46e1828340a6aa46204d","tabbable":null,"tooltip":null,"value":791656.0}},"8a20eba051344c61a0d9e7fccbf4d9f7":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"8ab759cafa2a465ebda207b423fd6c69":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c56d2f448c5450687d5c584f4ed6c0f":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_ee784e8043034d34a836ecbe58390441","placeholder":"​","style":"IPY_MODEL_ab7e07bfd0bf44d3acd8d7ba791a324f","tabbable":null,"tooltip":null,"value":" 927k/? [00:00&lt;00:00, 42.1MB/s]"}},"8c78e9010ab0403f9593cbec48e80965":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c9ac2a1bde249d68f64b4cabe13cb92":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_99abaef5aed14a75901ed10b57fc1059","placeholder":"​","style":"IPY_MODEL_a3805efbdeec4aed8e1180ea7f3d6c5c","tabbable":null,"tooltip":null,"value":" 2.37M/? [00:00&lt;00:00, 84.3MB/s]"}},"8e816eb265ff47c5b8cd1064ae66e560":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e856684dd084a9db9c13df67117afec":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f1a74f702fb40eca986f6be1794aa7d":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_da3bc08b97dd4d2686738fd0a10fbde1","placeholder":"​","style":"IPY_MODEL_01fd949b86f24a28a51b95fd668bb49c","tabbable":null,"tooltip":null,"value":"tokenizer.json: "}},"8f2546a947934aa68eba34ea22a30995":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_9577fd0654184975bf10c4baa23d0d36","placeholder":"​","style":"IPY_MODEL_f696f01d83bb4e6d9915ac0075772900","tabbable":null,"tooltip":null,"value":" 147/147 [00:00&lt;00:00, 5.02kB/s]"}},"937829ac6a08404c855a499bc784198f":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"9577fd0654184975bf10c4baa23d0d36":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97035e9b8f6a4909bacf0978aa9c5c35":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4cc4200dfc9340f1bb626829649d8e4b","IPY_MODEL_f5ddc9248fa746d09809296bb19790b3","IPY_MODEL_4db1cf6455cc403f939f7e896020ce54"],"layout":"IPY_MODEL_16db18e8ee994a3096d4cc91a0f6a62c","tabbable":null,"tooltip":null}},"97ad04444683492285aa7c4bbfbad1b2":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_8ab759cafa2a465ebda207b423fd6c69","max":60.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_7be48b4353494584afdc65671c489a7a","tabbable":null,"tooltip":null,"value":60.0}},"98f006235fc2456da78b133af9563af6":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"991d4b2d4cfb4e599cf90d3ac5be8f09":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_88c5c18de66c4e519f282c1c71ba2594","placeholder":"​","style":"IPY_MODEL_360cead321da467794664fb44dc6afe4","tabbable":null,"tooltip":null,"value":"tokenizer.json: "}},"99abaef5aed14a75901ed10b57fc1059":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a8a14c87802431899a9288ae13c18e6":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"9e7ffe11d409446893505c3f577936c6":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9eb47e212f874eb091205c973b125c24":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_d437d948932b46b1b22cf84c691ab675","placeholder":"​","style":"IPY_MODEL_a083a452af1e4639b403ce51c8a7b342","tabbable":null,"tooltip":null,"value":"generation_config.json: 100%"}},"9ec8d773d31e48868eda5c524516c16f":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_2991bb9a23434ed3a2e38d5748cabbcc","max":132.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_73b4748328354aefae10f3d38613de13","tabbable":null,"tooltip":null,"value":132.0}},"9f32a4bf4a9c4fedb4fc1112279fb6ac":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_5f3116eb259f493589601991ac3a635e","placeholder":"​","style":"IPY_MODEL_aeef0ce6aa0b4a9c985d3e8133a01910","tabbable":null,"tooltip":null,"value":" 251k/? [00:00&lt;00:00, 9.13MB/s]"}},"9f981f3a02e24346abbf819020cb2e91":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_15c0743e0bce44eaaaf830558c446e6e","placeholder":"​","style":"IPY_MODEL_a99a8bd25b094ceb9cc6abd0d2b2939a","tabbable":null,"tooltip":null,"value":"spiece.model: 100%"}},"a083a452af1e4639b403ce51c8a7b342":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"a1d4415524ea42b7a2c7d5876a07ccf0":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_267c9323a4ba4b499b18b906c07d8c6f","placeholder":"​","style":"IPY_MODEL_0bc6a34cc6a84375b4593222604fafd6","tabbable":null,"tooltip":null,"value":" 792k/792k [00:00&lt;00:00, 30.9MB/s]"}},"a2749441eeee4b80b7ba51a5e926a4f0":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3d098dec17624f2d956bde7c42ac57b6","IPY_MODEL_32df99900b9f4d61b3ca7face0ab1934","IPY_MODEL_e8a4f672c3c84808bf448b2503683df1"],"layout":"IPY_MODEL_f93d70c1e6f44605972b60bac9c3bd64","tabbable":null,"tooltip":null}},"a3805efbdeec4aed8e1180ea7f3d6c5c":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"a3ff9a31564e48f5b7af4de5d0f95a80":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"a4f85206eb5d4220b356587de914cff6":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"a99a8bd25b094ceb9cc6abd0d2b2939a":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"aa24d37535af4a6f8e26a83e76673626":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6f00d55aad724dfaa9925ab5e48b6f93","IPY_MODEL_43a25290e8d14ec3b02e1513a0a41b57","IPY_MODEL_cbf08cce393e40d6a5052fa8d0be9be0"],"layout":"IPY_MODEL_1589771b9cd142999992fcf133ab3282","tabbable":null,"tooltip":null}},"ab7e07bfd0bf44d3acd8d7ba791a324f":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"ace0176c2528441c860e5759dd95689b":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_4a51ea4d74af4fe5a960172b95fec56d","placeholder":"​","style":"IPY_MODEL_b7717e36baf144b7a5cffc14f5731972","tabbable":null,"tooltip":null,"value":"special_tokens_map.json: 100%"}},"aec1ee4a846e46398577a4551886fbac":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aeef0ce6aa0b4a9c985d3e8133a01910":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"af219e3a675e4ff7aa16b9bb5808be63":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_aec1ee4a846e46398577a4551886fbac","max":893.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_fefccbc151ed4abdbd88f4c8d2960fc3","tabbable":null,"tooltip":null,"value":893.0}},"af39951eae38488a88f98469a06659f1":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_522bb04eb82d400699748c1cc257ad2e","placeholder":"​","style":"IPY_MODEL_591bc91c41c440ea8c04152c9a56483c","tabbable":null,"tooltip":null,"value":" 445M/445M [00:07&lt;00:00, 75.6MB/s]"}},"af642622bd774b348b7307436e8aaca6":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b0b584c5704e46e1828340a6aa46204d":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b0d738a1a223403682fa9932edc484ff":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_e8f57fa572d544b2b7f36dd9a6ca1a7f","placeholder":"​","style":"IPY_MODEL_8a20eba051344c61a0d9e7fccbf4d9f7","tabbable":null,"tooltip":null,"value":"model.safetensors: 100%"}},"b5e6f2494f8f4e11b2c5bb04add558dc":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_23858fdfe0c54251a58296e298b466f9","placeholder":"​","style":"IPY_MODEL_3e22f7618a274bfebd1eafdac3a301d0","tabbable":null,"tooltip":null,"value":" 585k/? [00:00&lt;00:00, 28.5MB/s]"}},"b7717e36baf144b7a5cffc14f5731972":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"b93be011867d4e6a8c1c8d91dbc65002":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bdf7ffd3a19e433a8957c315529c3990":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_f898015de8584541b9d31bede45a7183","max":147.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_721f5ad5e42640b6b74248dec02c5137","tabbable":null,"tooltip":null,"value":147.0}},"bed65f5d5664497f860e772ad70df5fd":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9eb47e212f874eb091205c973b125c24","IPY_MODEL_9ec8d773d31e48868eda5c524516c16f","IPY_MODEL_13de6c20afcf4039893eb970ce9fe965"],"layout":"IPY_MODEL_c00906c3439b4927a36298b12f1c9aef","tabbable":null,"tooltip":null}},"bf0c06a3ded845988135cd662dc5740a":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf115e6275a7453db598bafe7f7ab746":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bfbfd959dc0e4d4a8d338a79a52f25d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"c00906c3439b4927a36298b12f1c9aef":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c35c40edfe904bfe89a536aad5d630b7":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4867c8abea74b49a2f067807107afec":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"c4b7511021ea43f59b66b6b5bc497b7e":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"c567d83b61d648499ef0d909c17cc583":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d328779c264845ce8979d4a8e355bc95","IPY_MODEL_35ad873b2a12440bb22efd08abc797b4","IPY_MODEL_8c56d2f448c5450687d5c584f4ed6c0f"],"layout":"IPY_MODEL_09066d6cbdb2471fbbeda6c6c7dc6696","tabbable":null,"tooltip":null}},"c7097c3939654be79e7dd91f34d34c30":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"c908853db22c472a911e07f047a3ebf4":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c9b71f7c5b364bde98a92434e42be96c":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ca104ef413ad441cbc8fbda5d0d8da4a":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_fff8607f8c844306915374d30b5a0e5b","max":444996256.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_fd8bd31b92bd4243a78ece2e570b3538","tabbable":null,"tooltip":null,"value":444996256.0}},"ca8dacb5ac934895801ef46131aa122e":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cad577edb3e847308e7be471dbeb6f7f":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbc6210bbf1347658159e88b70f1af8e":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbf08cce393e40d6a5052fa8d0be9be0":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_cdfb47e3433f481ab8ceff42280dc365","placeholder":"​","style":"IPY_MODEL_81ece22a38c84238ba58c6ae8f4f6549","tabbable":null,"tooltip":null,"value":" 385/385 [00:00&lt;00:00, 27.8kB/s]"}},"cce387c0ca5a40fb99a6ffc108d9fb70":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cdfb47e3433f481ab8ceff42280dc365":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d328779c264845ce8979d4a8e355bc95":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_75c8792a47384f599730954bbba40047","placeholder":"​","style":"IPY_MODEL_7aea3d9620904e4ea581361121d4f54d","tabbable":null,"tooltip":null,"value":"vocab.json: "}},"d3e031525a1c4d5d9b1e30ce6a8ca7f6":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d437d948932b46b1b22cf84c691ab675":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d50ad7115dcd45e3a535b3dd77785f9b":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_eacbccdcb97e49adb000ca6ef35110f2","placeholder":"​","style":"IPY_MODEL_a4f85206eb5d4220b356587de914cff6","tabbable":null,"tooltip":null,"value":"tokenizer_config.json: 100%"}},"d8165edb719e423f9f103cf676855fa3":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"da3bc08b97dd4d2686738fd0a10fbde1":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dbb83a7867c74ebba0c913247577a7ce":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0ee010f0e1d4c75a57efd4c2d3f419f":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_788c950f684a48fbb7257b4298651ebf","placeholder":"​","style":"IPY_MODEL_c4867c8abea74b49a2f067807107afec","tabbable":null,"tooltip":null,"value":"config.json: 100%"}},"e5a1a7e5253c4c52a010a95c6f246539":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"e8a4f672c3c84808bf448b2503683df1":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_c9b71f7c5b364bde98a92434e42be96c","placeholder":"​","style":"IPY_MODEL_4249d86a58cb403c9149d32fde9bb01e","tabbable":null,"tooltip":null,"value":" 1.21k/? [00:00&lt;00:00, 115kB/s]"}},"e8f57fa572d544b2b7f36dd9a6ca1a7f":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eacbccdcb97e49adb000ca6ef35110f2":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed9a0257ed2749b093300d65d4bcc872":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee053dceebc94e3ea95ebe8c67564865":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_fbab7ba76ff64ce49e8ee62fcd64fc76","placeholder":"​","style":"IPY_MODEL_98f006235fc2456da78b133af9563af6","tabbable":null,"tooltip":null,"value":" 893/893 [00:00&lt;00:00, 82.6kB/s]"}},"ee784e8043034d34a836ecbe58390441":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef57aad8add04b72b843914f271d06e2":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b0d738a1a223403682fa9932edc484ff","IPY_MODEL_ca104ef413ad441cbc8fbda5d0d8da4a","IPY_MODEL_af39951eae38488a88f98469a06659f1"],"layout":"IPY_MODEL_9e7ffe11d409446893505c3f577936c6","tabbable":null,"tooltip":null}},"f03af3b94df04614b9d55d3ec649bc4e":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f18799f85d264e08b89fa002fe62125d":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f59052039f52458b8367982bac9bbe7c":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5ddc9248fa746d09809296bb19790b3":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_870ca376e05e4de2bec9ea7fc71f5d5c","max":891646390.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_f18799f85d264e08b89fa002fe62125d","tabbable":null,"tooltip":null,"value":891646390.0}},"f696f01d83bb4e6d9915ac0075772900":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"f77b0afcebbd47e19d8f443b0c457285":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"f898015de8584541b9d31bede45a7183":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f93d70c1e6f44605972b60bac9c3bd64":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fbab7ba76ff64ce49e8ee62fcd64fc76":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc69f650e2a14f32985b031dd567b3ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3cf186a5cde2461184c7bfc5e4b21e3f","IPY_MODEL_ff2b09ed3b854299aa66243b7f3c5d73","IPY_MODEL_b5e6f2494f8f4e11b2c5bb04add558dc"],"layout":"IPY_MODEL_ed9a0257ed2749b093300d65d4bcc872","tabbable":null,"tooltip":null}},"fd8bd31b92bd4243a78ece2e570b3538":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fefccbc151ed4abdbd88f4c8d2960fc3":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ff2b09ed3b854299aa66243b7f3c5d73":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_0c644d2a2e2b4e9cbde44732928e840b","max":1.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_c908853db22c472a911e07f047a3ebf4","tabbable":null,"tooltip":null,"value":1.0}},"fff8607f8c844306915374d30b5a0e5b":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}},"version_major":2,"version_minor":0}}},"nbformat":4,"nbformat_minor":5}
